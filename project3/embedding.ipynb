{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d903b693",
   "metadata": {},
   "source": [
    "# INF264 - Obligatory assignment 3: Sequence Models\n",
    "\n",
    "By Einar Bernsen and Johannes Skivdal\n",
    "\n",
    "Initial imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f964bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\inf265_ob3\\Lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "d:\\conda\\envs\\inf265_ob3\\Lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "d:\\conda\\envs\\inf265_ob3\\Lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e24bbe0090>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "seed = 265\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28eedc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb94d0",
   "metadata": {},
   "source": [
    "#### Defining global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b92991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING = True\n",
    "CONTEXT_SIZE = 6\n",
    "EMBEDDING_SIZE = 16\n",
    "SAVE_PATH = \"./save_folder/\"\n",
    "TOKENIZER_EN = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e121d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired from the tutorial\n",
    "def read_files(datapath=\"./data_train/\"):\n",
    "    \"\"\"\n",
    "    Return a list of strings, one for each line in each .txt files in 'datapath'\n",
    "    \"\"\"\n",
    "    # Find all txt files in directory\n",
    "    files = os.listdir(datapath)\n",
    "    files = [datapath + f for f in files if f.endswith(\".txt\")]\n",
    "\n",
    "    # Stores each line of each book in a list\n",
    "    lines = []\n",
    "    for f_name in files:\n",
    "        with open(f_name) as f:\n",
    "            lines += f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48a5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_read = read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a3620c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268380"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a469f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(datapath):\n",
    "    # Get all files from the dataset\n",
    "    files = os.listdir(datapath)\n",
    "    files = [datapath + f for f in files if f.endswith(\".txt\")]\n",
    "\n",
    "    # Read all the lines into a list\n",
    "    lines = []\n",
    "    for f_name in files:\n",
    "        with open(f_name) as f:\n",
    "            lines += f.readlines()\n",
    "\n",
    "    # Tokenize every line\n",
    "    tokenized_lines = []\n",
    "    for line in lines:\n",
    "        tokenized_lines += TOKENIZER_EN(line)\n",
    "\n",
    "    # Return both, incase you want the original lines too.\n",
    "    return tokenized_lines, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b92a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to save and load here, lightweight to compute.\n",
    "train_token, train_lines = tokenize_dataset(\"./data_train/\")\n",
    "val_token, val_lines = tokenize_dataset(\"./data_val/\")\n",
    "test_token, test_lines = tokenize_dataset(\"./data_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5a138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset:      2684706\n",
      "Total number of words in the validation dataset:    49526\n",
      "Total number of words in the test dataset:          124152\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of words in the training dataset:     \", len(train_token))\n",
    "print(\"Total number of words in the validation dataset:   \", len(val_token))\n",
    "print(\"Total number of words in the test dataset:         \", len(test_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf34bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From tutorial\n",
    "def yield_tokens(lines, tokenizer=TOKENIZER_EN):\n",
    "    \"\"\"\n",
    "    Yield tokens, ignoring names and digits to build vocabulary\n",
    "    \"\"\"\n",
    "    # Match any word containing digit\n",
    "    no_digits = \"\\w*[0-9]+\\w*\"\n",
    "    # Match word containing a uppercase\n",
    "    no_names = \"\\w*[A-Z]+\\w*\"\n",
    "    # Match any sequence containing more than one space\n",
    "    no_spaces = \"\\s+\"\n",
    "\n",
    "    for line in lines:\n",
    "        line = re.sub(no_digits, \" \", line)\n",
    "        line = re.sub(no_names, \" \", line)\n",
    "        line = re.sub(no_spaces, \" \", line)\n",
    "        yield tokenizer(line)\n",
    "\n",
    "\n",
    "def create_vocabulary(lines, min_freq=100):\n",
    "    \"\"\"\n",
    "    Create a vocabulary (list of known tokens) from a list of strings\n",
    "    \"\"\"\n",
    "    # vocab contains the vocabulary found in the data, associating an index to each word\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        yield_tokens(lines), min_freq=min_freq, specials=[\"<unk>\"]\n",
    "    )\n",
    "    # Since we removed all words with an uppercase when building the vocabulary, we skipped the word \"I\"\n",
    "    vocab.append_token(\"i\")\n",
    "    # Value of default index. This index will be returned when OOV (Out Of Vocabulary) token is queried.\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3e05d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading the vocab\n",
    "if os.path.isfile(SAVE_PATH + \"train_vocab.pt\"):\n",
    "    train_vocab = torch.load(SAVE_PATH + \"train_vocab.pt\")\n",
    "else:\n",
    "    # Creating the vocab\n",
    "    train_vocab = create_vocabulary(train_lines)\n",
    "    torch.save(train_vocab, SAVE_PATH + \"train_vocab.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1988c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset:      2684706\n",
      "Number of distinct words in the training dataset:   52105\n",
      "The size of the defined vocabulary:                 1880\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of words in the training dataset:     \", len(train_token))\n",
    "print(\"Number of distinct words in the training dataset:  \", len(set(train_token)))\n",
    "print(\"The size of the defined vocabulary:                \", len(train_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40787791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"I\" is not in the vocab, so it will have index 0, that stands for unknown word.\n",
    "train_vocab[\"I\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157aa9e",
   "metadata": {},
   "source": [
    "### Function for creating datasets\n",
    "\n",
    "Instead of excluding all banned words, we could introduse some RNG to determine when to exclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc9b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of the indexes that should be excluded\n",
    "banned_words = train_vocab.lookup_indices([\"<ukn>\", \".\", \",\", \"(\", \")\", \"?\", \"!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "535bfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(dataset):\n",
    "    context_data = torch.tensor([ex[0] for ex in dataset])\n",
    "    target_data = torch.tensor([ex[1] for ex in dataset])\n",
    "    dataset = TensorDataset(context_data, target_data)\n",
    "    return dataset, context_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfa3cf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.empty(0), torch.tensor([1]), torch.tensor([0])), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "194228c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in the tokenised data and a vocabulary. Then creates context and target pairs, based on the context size and what position the target should have to the context.\n",
    "def create_dataset(tokens, vocab, context_size, banned_words=[-1], only_words=None, position='middle'):\n",
    "    # The position needs to be defined by the following\n",
    "    assert position in [\n",
    "        \"middle\",\n",
    "        \"behind\",\n",
    "        \"ahead\",\n",
    "    ], \"\"\"Position needs to either 'middle', 'behind' or 'ahead'.\"\"\"\n",
    "\n",
    "    data = []\n",
    "\n",
    "    token_len = len(tokens)\n",
    "\n",
    "    if only_words:\n",
    "        TARGET_MAP = {only_words[i]: i for i in range(len(only_words))}\n",
    "\n",
    "    if position == \"middle\":\n",
    "        window_size = context_size // 2\n",
    "        end_pos = token_len - window_size\n",
    "        start_pos = window_size\n",
    "\n",
    "    elif position == \"ahead\":\n",
    "        end_pos = token_len\n",
    "        start_pos = context_size\n",
    "\n",
    "    elif position == \"behind\":\n",
    "        end_pos = token_len - context_size\n",
    "        start_pos = 0\n",
    "\n",
    "    for i in range(start_pos, end_pos):\n",
    "        if train_vocab[tokens[i]] in banned_words:\n",
    "            continue\n",
    "\n",
    "        if only_words:\n",
    "            if tokens[i] not in only_words:\n",
    "                continue\n",
    "\n",
    "        if position == \"middle\":\n",
    "            context = tokens[i - window_size : i] + tokens[i + 1 : i + window_size + 1]\n",
    "\n",
    "        elif position == \"ahead\":\n",
    "            context = tokens[i - context_size : i]\n",
    "\n",
    "        elif position == \"behind\":\n",
    "            context = tokens[i + 1 : i + context_size + 1]\n",
    "\n",
    "        if only_words:\n",
    "            target_idx = TARGET_MAP[tokens[i]]\n",
    "        else:\n",
    "            target = tokens[i]\n",
    "            target_idx = vocab[target]\n",
    "\n",
    "        context_idxs = [vocab[x] for x in context]\n",
    "        \n",
    "        data.append((context_idxs, target_idx))\n",
    "\n",
    "    context_data = torch.tensor([ex[0] for ex in data])\n",
    "    target_data = torch.tensor([ex[1] for ex in data])\n",
    "    dataset = TensorDataset(context_data, target_data)\n",
    "\n",
    "    return dataset, context_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8aaff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(\n",
    "    train_token, train_vocab, CONTEXT_SIZE, banned_words, position=\"middle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "438dfb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1917177, 2684706)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quite the amount of data removed\n",
    "len(train_dataset[0]), len(train_token)\n",
    "#(1917177, 2684706)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d1771",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Implementing CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5a481a8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(\n",
    "        self, emb_dim=EMBEDDING_SIZE, context_size=CONTEXT_SIZE, vocab_size=-1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.fc1 = nn.Linear(emb_dim * context_size, 128)\n",
    "        self.fc2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = torch.flatten(self.embeddings(x), 1)\n",
    "        x = F.relu(self.fc1(embeddings))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f463ad7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e75bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read through: https://medium.com/@zergtant/use-weighted-loss-function-to-solve-imbalanced-data-classification-problems-749237f38b75\n",
    "# Using inversely proportional frequency\n",
    "def compute_class_weights(targets):\n",
    "    class_counts = torch.tensor(np.bincount(targets))\n",
    "    class_counts = class_counts.masked_fill(class_counts == 0, 999999999)\n",
    "    \n",
    "    return targets.size(0) / class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d0f93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cbow(\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    emb_dim=EMBEDDING_SIZE,\n",
    "    context_size=CONTEXT_SIZE,\n",
    "    lr=0.001,\n",
    "    loss_weights = None\n",
    "):\n",
    "    print(\"Starting training\")\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    cbow_model = CBOW(\n",
    "        vocab_size=len(train_vocab), emb_dim=emb_dim, context_size=context_size\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(cbow_model.parameters(), lr=lr)\n",
    "    loss_fnc = nn.CrossEntropyLoss(weight=loss_weights).to(device)\n",
    "\n",
    "    print(\n",
    "        f\"\\nStarting training with emb_dim = {emb_dim}, context_size = {context_size}: \"\n",
    "    )\n",
    "    for epoch in trange(epochs, desc=\"Epoch\"):\n",
    "        for context, target in train_dataloader:\n",
    "            context = context.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = cbow_model(context)\n",
    "            loss = loss_fnc(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss {loss}\")\n",
    "\n",
    "    return cbow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2572bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_dataloader(model_temp, dataloader, hidden_arg=None):\n",
    "    accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_temp.eval()\n",
    "\n",
    "        for context, target in dataloader:\n",
    "            context = context.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            if hidden_arg:\n",
    "                hidden = model.init_hidden(len(target)).to(device)\n",
    "                output, _ = model_temp(context,hidden)\n",
    "            else:\n",
    "                output = model_temp(context)\n",
    "\n",
    "            accuracy += (\n",
    "                torch.nan_to_num(output.argmax(dim=1) == target).count_nonzero()\n",
    "                / dataloader.batch_size\n",
    "            )\n",
    "\n",
    "    return accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3792d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(cbow_model, train_dataloader, val_dataloader):\n",
    "    print(\"Starting evaluation\")\n",
    "    train_accuracy = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        cbow_model.eval()\n",
    "\n",
    "        print(\"\\nComputing training accuracy\")\n",
    "        train_accuracy = evaluate_model_dataloader(cbow_model, train_dataloader)\n",
    "        print(\"done\")\n",
    "\n",
    "        print(\"\\nComputing validation accuracy\")\n",
    "        val_accuracy = evaluate_model_dataloader(cbow_model, val_dataloader)\n",
    "        print(\"done\")\n",
    "\n",
    "    print(\"Model scored following results\")\n",
    "    print(\"Train accuracy: \", train_accuracy)\n",
    "    print(\"Val accuracy: \", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6357792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_load(filepath, saving_item=None, force_save=False):\n",
    "    if not os.path.isfile(filepath) or force_save:\n",
    "        torch.save(saving_item, filepath)\n",
    "    else:\n",
    "        saving_item = torch.load(filepath)\n",
    "\n",
    "    return saving_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb40d4ef",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def save_load_model(filepath, model_instance=None, model=None, force_save=False):\n",
    "    if not os.path.isfile(filepath) or force_save:\n",
    "        torch.save(model, filepath)\n",
    "    else:\n",
    "        assert (\n",
    "            model_instance\n",
    "        ), \"If you want overwrite an existing model, then enter force_save=True\"\n",
    "\n",
    "        model = model_instance\n",
    "        model.load_state_dict(torch.load(filepath).state_dict())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d5f9c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Creating grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5c0c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cbow_grid(epochs, context_sizes: list, embedding_sizes: list, use_class_weights=False):\n",
    "    models_result = {}\n",
    "\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "    best_model_perf = 0.0\n",
    "\n",
    "    for con_size in context_sizes:\n",
    "        print(f\"\\nCreating datasets for context size: {con_size}: \")\n",
    "        train_dataset_temp, _, train_targets = create_dataset(\n",
    "            train_token, train_vocab, con_size, banned_words, position=\"middle\"\n",
    "        )\n",
    "        val_dataset_temp, _, _ = create_dataset(\n",
    "            val_token, train_vocab, con_size, banned_words, position=\"middle\"\n",
    "        )\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset_temp, batch_size=1024, shuffle=True)\n",
    "        val_dataloader = DataLoader(val_dataset_temp, batch_size=1024, shuffle=True)\n",
    "        print(\"Datasets created\")\n",
    "\n",
    "        if use_class_weights == True:\n",
    "            class_weights = compute_class_weights(train_targets)\n",
    "        else:\n",
    "            class_weights = None\n",
    "\n",
    "        for emb_size in embedding_sizes:\n",
    "            model = train_cbow(\n",
    "                epochs, train_dataloader, emb_dim=emb_size, context_size=con_size, loss_weights=class_weights\n",
    "            )\n",
    "            validation_performance = evaluate_model_dataloader(model, val_dataloader)\n",
    "\n",
    "            results_info = {}\n",
    "\n",
    "            results_info[\"Parameters\"] = {\"con_size\": con_size, \"emb_size\": emb_size}\n",
    "            results_info[\"Val_perf\"] = validation_performance.item()\n",
    "\n",
    "            if validation_performance.item() > best_model_perf:\n",
    "                best_model_perf = validation_performance.item()\n",
    "                best_model = model\n",
    "                best_params = (con_size, emb_size)\n",
    "\n",
    "            models_result[f\"{con_size},{emb_size}\"] = results_info\n",
    "\n",
    "    return best_model, best_params, best_model_perf, models_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68617ef8",
   "metadata": {},
   "source": [
    "Skip these next 5 cells if not TRAINING==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bf97dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating datasets for context size: 4: \n",
      "Datasets created\n",
      "Starting training\n",
      "\n",
      "Starting training with emb_dim = 12, context_size = 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [00:11<01:39, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 4.387630939483643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [00:21<01:26, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 4.061700344085693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 3/10 [00:31<01:13, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 4.032505512237549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 4/10 [00:42<01:03, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 3.9217262268066406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 5/10 [00:52<00:52, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 4.206316947937012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 6/10 [01:02<00:41, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 3.8075170516967773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 7/10 [01:13<00:31, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 4.459645748138428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 8/10 [01:23<00:20, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 4.14863920211792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 9/10 [01:33<00:10, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 4.2407708168029785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [01:43<00:00, 10.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 3.8415980339050293\n",
      "Starting training\n",
      "\n",
      "Starting training with emb_dim = 16, context_size = 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [00:10<01:31, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 4.608013153076172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [00:20<01:22, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 4.472213268280029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 3/10 [00:30<01:11, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 4.12794303894043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 4/10 [00:40<01:00, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 4.20465612411499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 5/10 [00:50<00:50, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 3.6004111766815186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 6/10 [01:00<00:40, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 4.327670097351074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 7/10 [01:10<00:30, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 4.000092506408691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 8/10 [01:20<00:20, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 4.086477756500244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 9/10 [01:30<00:10, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 4.012253284454346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [01:40<00:00, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 3.9939897060394287\n",
      "\n",
      "Creating datasets for context size: 6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created\n",
      "Starting training\n",
      "\n",
      "Starting training with emb_dim = 12, context_size = 6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [00:10<01:30, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 4.774755477905273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [00:20<01:19,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 4.586620807647705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 3/10 [00:29<01:09,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 4.381562232971191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 4/10 [00:40<01:00, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 4.230799674987793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 5/10 [00:50<00:50, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 4.152810096740723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 6/10 [01:00<00:40, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 4.134964942932129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 7/10 [01:10<00:30, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 4.344654083251953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 8/10 [01:20<00:20, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 4.138851165771484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 9/10 [01:30<00:10, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 4.5815205574035645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [01:40<00:00, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 4.1146240234375\n",
      "Starting training\n",
      "\n",
      "Starting training with emb_dim = 16, context_size = 6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [00:10<01:32, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 4.449157238006592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [00:20<01:22, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 4.151708126068115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 3/10 [00:30<01:10, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 4.403507232666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 4/10 [00:40<01:00, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 3.892160177230835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 5/10 [00:50<00:50, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 3.8412320613861084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 6/10 [01:00<00:40, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 4.031732559204102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 7/10 [01:10<00:30, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 4.298315048217773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 8/10 [01:20<00:20, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 4.211244106292725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 9/10 [01:30<00:10, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 4.039017200469971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [01:40<00:00, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 3.8218367099761963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    best_model, best_params, best_model_perf, models_result = train_cbow_grid(\n",
    "        10, context_sizes=[4, 6], embedding_sizes=[12, 16], use_class_weights=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9357ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6,16', 0.2871907651424408)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_key = max(models_result, key=lambda key: models_result[key][\"Val_perf\"])\n",
    "best_model_key, models_result[best_model_key][\"Val_perf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca015be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (embeddings): Embedding(1880, 16)\n",
       "  (fc1): Linear(in_features=96, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1880, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1b621cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: 6,16 with 0.2872% on validation\n",
      "#2: 6,12 with 0.2847% on validation\n",
      "#3: 4,16 with 0.2843% on validation\n",
      "#4: 4,12 with 0.2746% on validation\n"
     ]
    }
   ],
   "source": [
    "for i, key in enumerate(\n",
    "    sorted(models_result, key=lambda key: models_result[key][\"Val_perf\"], reverse=True)\n",
    "):\n",
    "    print(f\"\"\"#{i+1}: {key} with {models_result[key]['Val_perf']:.4f}% on validation\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70ffb988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_SIZE, EMBEDDING_SIZE = best_params  # (6, 16)\n",
    "CONTEXT_SIZE, EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16a765",
   "metadata": {},
   "source": [
    "Start from here if TRAINING=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97aa4013",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    save_load_model(\n",
    "        filepath=SAVE_PATH + \"CBOW_model.pth\", model=best_model, force_save=True\n",
    "    )\n",
    "    embedding_weights = best_model.embeddings.weight\n",
    "    embedding_dict = best_model.embeddings.state_dict()\n",
    "\n",
    "    embedding_weights = save_load(SAVE_PATH + \"CBOW_embeddings.pt\", saving_item=embedding_weights, force_save=True)\n",
    "    embedding_dict = save_load(SAVE_PATH + \"CBOW_embeddings_dict.pt\", saving_item=embedding_dict, force_save=True)\n",
    "else:\n",
    "    best_model = torch.load(SAVE_PATH + \"CBOW_model.pth\")\n",
    "    embedding_weights = best_model.embeddings.weight\n",
    "    embedding_dict = best_model.embeddings.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f657e0eb",
   "metadata": {},
   "source": [
    "#### Evaluating on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5406fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_temp, _, _ = create_dataset(\n",
    "    test_token, train_vocab, CONTEXT_SIZE, banned_words, position=\"middle\"\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset_temp, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6bed9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on unseen test data: 0.2915%\n"
     ]
    }
   ],
   "source": [
    "print(f'Model performance on unseen test data: {evaluate_model_dataloader(best_model, test_dataloader).item():.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617b6a4d",
   "metadata": {},
   "source": [
    "### Checking similarities between the words using the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "536810d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000, -0.1986, -0.1889,  ...,  0.2937,  0.4111, -0.0624],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CosineSimilarity(dim=1)(embedding_weights[0], embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba98f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = {}\n",
    "for word in range(len(train_vocab)):\n",
    "    similarities[train_vocab.lookup_tokens([word])[0]] = torch.topk(\n",
    "        nn.CosineSimilarity(dim=1)(embedding_weights[word], embedding_weights), 11\n",
    "    )[1][1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df043fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words = train_vocab.lookup_tokens(range(len(train_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eca44a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_checker(in_word=None):\n",
    "    if in_word:\n",
    "        word_sim = in_word\n",
    "    else:\n",
    "        word_sim = random.choice(vocab_words)\n",
    "    print(\"\\nThe word:\", word_sim)\n",
    "    print(\"The similar words: \", train_vocab.lookup_tokens(similarities[word_sim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "867f7058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The word: king\n",
      "The similar words:  ['earl', 'count', 'prince', 'weather', 'bishop', 'princess', 'wind', 'general', 'dwarf', 'latter']\n",
      "\n",
      "The word: queen\n",
      "The similar words:  ['horses', 'artillery', 'leaves', 'houses', 'darkness', 'dogs', 'water', 'money', 'doctor', 'shore']\n",
      "\n",
      "The word: boy\n",
      "The similar words:  ['brother', 'dog', 'beast', 'ship', 'master', 'servant', 'story', 'kingdom', 'son', 'company']\n",
      "\n",
      "The word: girl\n",
      "The similar words:  ['lady', 'dog', 'creature', 'man', 'gentleman', 'bird', 'laugh', 'fellow', 'letters', 'convent']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_checker(\"king\"), similarity_checker(\"queen\"), similarity_checker(\"boy\"), similarity_checker(\"girl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "142dbb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The word: motionless\n",
      "The similar words:  ['names', 'ships', 'troops', 'together', 'influence', 'evident', 'luck', 'sous', 'anger', 'hands']\n",
      "\n",
      "The word: persons\n",
      "The similar words:  ['men', 'people', 'women', 'days', 'kings', 'others', 'things', 'hours', 'years', 'sous']\n",
      "\n",
      "The word: figure\n",
      "The similar words:  ['son', 'path', 'rope', 'chief', 'impression', 'sons', 'firm', 'kingdom', 'own', 'lot']\n",
      "\n",
      "The word: eyes\n",
      "The similar words:  ['fingers', 'mouth', 'legs', 'nose', 'forces', 'tears', 'neck', 'hands', 'shoes', 'shoulders']\n",
      "\n",
      "The word: whose\n",
      "The similar words:  ['my', 'your', '-', 'his', 'our', 'their', 'whom', 'de', 'who', 'her']\n",
      "\n",
      "The word: countess\n",
      "The similar words:  ['soldiers', 'sun', 'dwarf', 'prince', 'count', 'someone', 'bondes', 'doctor', 'circumstances', 'kings']\n",
      "\n",
      "The word: fifteen\n",
      "The similar words:  ['three', 'six', 'forty', 'ten', 'five', 'two', 'social', 'infantry', 'seven', 'eight']\n",
      "\n",
      "The word: why\n",
      "The similar words:  ['where', 'how', 'what', 'until', '—', 'however', 'when', 'whether', 'as', '?']\n",
      "\n",
      "The word: oath\n",
      "The similar words:  ['name', 'opportunity', 'sewer', 'object', 'worse', 'idea', 'confusion', 'instinct', 'attached', 'midst']\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 10):\n",
    "    similarity_checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a96c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the embeddings compatible with the tensorflow visual site\n",
    "embedding_weights_cpu = embedding_weights.clone().to(\"cpu\")\n",
    "\n",
    "\n",
    "def temp_func(in_list):\n",
    "    ret_string = \"\"\n",
    "    for ele in in_list:\n",
    "        ret_string += f\"{ele}\\t\"\n",
    "    return ret_string\n",
    "\n",
    "\n",
    "with open(SAVE_PATH + \"Embedding.TSV\", \"w\") as file:\n",
    "    for n in range(len(embedding_weights_cpu)):\n",
    "        file.write(f\"{temp_func(embedding_weights_cpu[n])}\" + \"\\n\")\n",
    "\n",
    "with open(SAVE_PATH + \"Embedding_names.TSV\", \"w\") as file:\n",
    "    for n in range(len(embedding_weights_cpu)):\n",
    "        file.write(f\"{train_vocab.lookup_tokens([n])[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53b8ce",
   "metadata": {},
   "source": [
    "# 4 (dependency of 2.2)\n",
    "## 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba511aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pe(context_size, emb_size):\n",
    "    position_matrix = torch.zeros(context_size, emb_size)\n",
    "    for i in range(0, context_size - 1):\n",
    "        for j in range(0, int(emb_size / 2)):\n",
    "            position_matrix[i, 2 * j] = torch.sin(\n",
    "                torch.tensor(i / 10000 ** (2 * j / emb_size))\n",
    "            )\n",
    "            position_matrix[i, 2 * j + 1] = torch.cos(\n",
    "                torch.tensor(i / 10000 ** (2 * j / emb_size))\n",
    "            )\n",
    "    return position_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d9ff288",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = create_pe(CONTEXT_SIZE + 100, EMBEDDING_SIZE + 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "841b3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d122b363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e276c32290>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAGhCAYAAADssYQCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+wUlEQVR4nO2deZgU9bX+T1XvPdOzMTsMMIMDiIgiIG4RjFvcEq9J3KNm+UWDGtHkarzm3pDcCNEkhEQTvXoTg1eNJlETE5eIG2pQ2RVRAWXYGQaYfem16veHT+p8z7fpSjGZGWx4P8/D83y73u6u6prR6jrvvOcYtm3bBAAAAABXzAN9AAAAAEA+gAsmAAAA4AFcMAEAAAAP4IIJAAAAeAAXTAAAAMADuGACAAAAHsAFEwAAAPAALpgAAACAB3DBBAAAADyACyYAAADggQN6wfzVr35F9fX1FA6HacqUKfTaa68dyMMBAAAAcnLALpiPPfYYzZ49m2677TZatWoVfepTn6KzzjqLtmzZcqAOCQAAAMiJcaCar0+fPp2OOeYYuueee5xthx9+OJ1//vk0b94819dalkU7duygWCxGhmEM9qECAAA4iLFtm7q6uqi2tpZMM/d9pH8Ij8khmUzSihUr6Dvf+Y7YfsYZZ9CSJUuynp9IJCiRSDiPt2/fThMmTBj04wQAAHDosHXrVhoxYkRO/YBcMPfs2UOZTIaqqqrE9qqqKmpubs56/rx58+j73/9+1vYR3/sumeEwvf3534jtRz3+FWcNDdqhrKnboUGDtu//Tjq7LRp1zCaKxWLkxgG5YP4DvZxq2/Y+S6y33nor3XTTTc7jzs5Oqqurowe/8FsqjJn0H3s+JZ7/sy/+0Vn/JtkgtJs+97KzXmSUCO3Cs1Y76zUBeQwzP/2Rs94aSgjtyBP5It8e6RXa6Gltzjoe7RNaxVE9ztoukO8Zm8CPzYKk0MKNGWcdKswIzT+a15FCWW03R/K5LSgUEhm1vpwaVftzaxV8oopiWiljmItWFsytlbpoJbk1oziUWyty0WIuWmE/tYLwgGtmdP81dft+aRFo0A5uLev/LZR9TdI5IBfM8vJy8vl8WXeTLS0tWXedREShUIhCoVDWdgAAAGCoOCB/JRsMBmnKlCm0aNEisX3RokV0wgknHIhDAgAAAFw5YCXZm266ib70pS/R1KlT6fjjj6f77ruPtmzZQtdcc82BOiQAAAAgJwfsgnnRRRfR3r176Qc/+AHt3LmTJk6cSM888wyNGjXK83tU+pIU85m0fMFksf3nd77hrCf+3xVCe/+aXznr+me+JrTVn7nLWZ/+tnzdwiMWOuvbd5wttOuGv+isH2yfKrTLR7zlrJ/rkZ/tnBFrnfXyhDQHTxre5Kw/TMm6+hHVO531trT0PkdX7XXWezLSM60c1umsO6240IpL2U/ts6VnGi3m90nYaaEFYrz/lC39VF9hOqdmRFnL2JbQKJzJrQW1xwp2wEXz505P2QEXzeV15Mstkc/ldWb/NLsfmu1iybhpNNQaAHnAAf2jn1mzZtGsWbMO5CEAAAAAnkAvWQAAAMADB/QO81/lrFe/QWYkTI2PvCW233jjdGfd8IBstff3q7hsV/97+X6+z3DNKPVshdAOnxx11m8uGS+0By7hkux1y48V2uITuAR81YaLhfbfDU8664f2yj92OrX4PWf9Wu9YoZ1U9qGzXpOsFtrRpduc9cZ0VGiNJbud9Y6MrI/VlbQ761ZLll0rYlyu7bZTQisu5NJur17KLWBNL8kGw/w+adKiMSF+bJEWjQnlLtcaSrk2q5QbcNHcyqcumj0ImutXWDctV7nTcNmXi9bfUq5rmdcNlHlBHoA7TAAAAMADuGACAAAAHsAFEwAAAPBAXnuYYxd0k9+XovTxk8T2Vx8scNbVzcuF9tXlVzrr0S+tFtpP9x7jrGue2ym0d77NftzwxdIDsy7hx+GlMh5SczI/3rB2uNAmjmMP6cXN0qf89jRu4XfdTulv3lL3jLP+U/sUoU0p2OSs18TrhHZkbLuz3pQuFVpD4R5n3ZyRXZVGFLY7672a91lR0O2suyzpRZZEVH9Tep8FEY6jxLWoSjjCXqjufQZC/Fzd+zSDLt5nUD5XxXDzN11jJf2NjuSW+hMdIaLcXl5/fE+ifnufbvTb3+wv8D7BAIM7TAAAAMADuGACAAAAHsjrkqzVtJUsI0C7HpMTSYZ/maMkbV84Rmjlj3E5ySyVZcmFr3J5s/FDGVWZu527+xS82SS0F/p4JEzVUjmtZE+GIxll78jvJ9Ev8OSN1Loi+RmO40jI2i01QhvXwJ133to9WmhfKuMuR3ftOlVo55WtctbvxWV5uDGyy1lvSpULbWSk1VnvtmRUpSbC3YNaLfnrVB5Ry7WyjKeWaxNaGbQglFQ0Wa4NBXN3DwoqmkXyPX1+S9HksRgeNbc4yn5FVfpTWv0nWs5y7VDHNQahXPuJKuWCQxrcYQIAAAAewAUTAAAA8AAumAAAAIAH8trD3HXV0eQLhenvU+eL7RdmznDWhV/bLjT/eTzNo+Wyo4Q28hn2wPx1I4S24u8c0WjY/YbQfrn108468K70N1/qq3XWw97pFtrOND8u/UBI5DP4u0xgY0RopZ/mx1t3lAmtbgJ7ae+2yrZ5s5VJJk/ulXGUi8qXOuuVvaOFNjrMkZOtqWFCGxFpc9a7MwVCqwjz5+uwAvIzhNjr1f3NWEiNnEhvMBpSIydSCwVy+5v+gBo50f3N3JETU4mVZPmbvtzTUdSvoln+Zj+nlfTHc7Rd4yH7/37/mtY/f9MN+JtgKMEdJgAAAOABXDABAAAAD+R1Sfayrz5P4UI/vdAnYxDNlx3hrF8eJ8u1F/uUcu0XZTefyL/xNI9dF8vuQcMXK+XaETKSsW4Fl2vHtL8ptAd3cJce34ZtQlsS53JtyfoeobUocZSijbKUpZZrQ1uDQisyw866ublEaLUT+X0+aKsUWl11u7N+rFdqx5RvctZ6ubYmwK9rTsv9VYc4ctJuybLysBB/vh5b/hoWBzk2E9eqeIXBpKK5lWSlFlDKrlnlWhErka8zfXlernWNawxCudYNlGtBnoM7TAAAAMADuGACAAAAHsAFEwAAAPBAXnuYVxdvoqKYSUfee53YfuJVbzvrzWlpLHScw/7mw+N+IrRvJDke0nd2p9Aqr2521u2fbhRaFScyyFcuYxdr32N/c2zbUqE9uYfb9vmamoW2MsFxkeJNcaG1ZTiSUbhVSDKO0pzb32zZK1vxVSieW1On/AzVVXwuNsdljGViKR/AuoRs4VcZ4Ne1ZGJCGxZgD7PdCgutOMCft0vzNwv8qocpJIoEeCJKSvMU3fxNv4u/6fOpPqXmb5q5fUrDpTXeoPibuTzA/rbaG2p/0w34m+ATAu4wAQAAAA/gggkAAAB4IK9Lsl/c8BnyF4Ro9F1rxfZ7r3nNWY99+RtCi1zY5ayrfLJkmZk+wVnfedSjQvvFnvHOesfMMUKb8JMWZx2fNFpoZW/7nLUZlqXHNzbWO+vDdr8jtBc7+ViCm/cKbUOau+YUbpPTPHotLllGmmUdSC3X0m45JLrY5HPR3C7Lp+U+LnVu7ZETXirL+Xy+lJggtBNiG3h3aVkCLg9wF6D2jJyAUhLgknOv1iGoSERO5Pe9goBarpVlvLCfz1NGL9cqJVldU8u1Ge09TZ9LHMV0iZy4lFbdNNeyXq6vvoNQWh3y7kFuoFwLhhDcYQIAAAAewAUTAAAA8AAumAAAAIAH8trDjP+ihvyBMBUU7hDbF/VxG7aG/5Gv+dGDDzjrm3d+Smibz+bXnROVUY5fKdNLzjt2ldDWbWL/ateFtUKrfZXjE0bDSKGF1int4rQIwWvN7JOWtsjPt6yvwVlHtncJbWeGfbzCnfI91ZhCeLf8rhQy2CtMtMo2diUm/5o0d0l/s8LHnmJzXPqUlSV8bGv75PSX+hC3IWzNFAqtVPEwO7XISZGfJ5n0apGTwoA65UQaQxG/EjnRvMig36Wlns9lyoniYe6Pv2n4cvubXlvjZUVO+hMrceOT5Kt9gvzNIeeT9HMAuMMEAAAAvIALJgAAAOCBvC7Jhp5fSX4jQB/87DixfdZzVznrxtfeEtrRQf7IL/1ZDlGecR53CHonqXXXOZFLijdWyMjJN3zcIcie1iE0//08EaX9tLFCK13HZTXfMNlBp6WJu+0U934otDfauVxr7GoV2gZlwHN0Z0JonRZ/psju3OWqQJtPPI4YHDnp6JQRkJjJNaPmHlmSLTGVcm1CalOiPGhb7xBU6le7AMn9Ffn5PXtsGQsq8KmxEu0zKCVZvUNQUJRdJX6ltJrVIchjrETHdCkVGv2Mo+TsENSf7kD/jHzpEDQIDHnkBHyiwB0mAAAA4AFcMAEAAAAP4IIJAAAAeCCvPczEmcdQJhCmx8//udh+6/lXOWt72pFC+0kr+2Oj/9AitB98/W/O+ooNlwht50z2heoDMgZhNo521l8d94bQ/qZMBdk7SRogDb9vd9bWaOnjFTSxB2f45Y9pdfNwZz2idYPQ3u7j6EqgRUZOmpVBHJE90nNTp3SEWnO31LM7pG9YqMRR9vZIv7HYZN9wd1yesxIfR0f2pGRUZVKUJ6C0ZwrkeyoeZpcWOSnwq7ES6WFGlSknKcodOUnqkROfS9s8F80tciJ9SiunpuPeNq8fsRK3r8ufJC8yT1rqDTnwU4cc3GECAAAAHsAFEwAAAPBAXpdko9/cQf6CkJimQURkvf2+s15/3zShffTsac66YZ0sn5b5eIJH83N1Qrvg4jed9ZtxOWR471SOclxSJKeOPB86lY93YpvQjB9z5KTtnMOFVrKR92FqkZPebVzetFNJoa3oULoJ7ZX725jm94m0yMhJhxI5CbW6RE7a9Q5B/CvU0yVLpGrkZE+fVpI1eX+tSVl2LYlx2XxHqkRohT5+XY8lJ64U+Vnr1TQ5eFqWa8M+tQuQkCikdAHSIycBNVailV19Zu7Iic9lgLRb5EQtwXmOnGhlOxE56W/ZtZ/0O3KSJyBycvCDO0wAAADAA7hgAgAAAB7ABRMAAADwQF57mI8d9jcqipl02PM3iO31bFPSQ6fJcSX/feEVzto4SvqG97Wz51f3zF6h3Xj9q876mo1fFNruY9kXqvFrkZPR7IVe3LBCaC+1s3fXPk4aIKOf5EiIVVshtIJtigdnSj/ugz2Vzrq2a6PQ3otzHMWvxGuIiHZneP+RttyRk2CHS+SkW/46RZXISXuf5m8a7A3uTejt9tiLbEtJf7M22s7vqUVOoqbqUwaEFnFpmxf2KdNKNDMtYPJn1yMnfsWn3J/IiSmmjgxM5CSnBzgY8RBETj75wE8dFHCHCQAAAHgAF0wAAADAA3ldkr2nvYHCaT8dfmen2L7x+1z+mxqSERB7+bv8vLnHC23+kjOc9di1y4Q2Qim1bnh9tNCOO+UDZ70+JUudnRM5cvJvRauF9rJ/Bh/XOPk6cxt3Ieo8uUFohVuVKSfFcgpIVzN3zbETMjryXjcPtzba5DnbkeHXhVplTKfb4vcJduQuV/k7ZakzYPDj3h6tK48SOWnTSrJFBu+vPa2Xa7nTz65UsdRcIieFPrULkF6uVWMl8jukKNdqHz3gMuXE5zatxCVyMhBTTrxs/1iUD7OGUg8hiJyAfAB3mAAAAIAHcMEEAAAAPIALJgAAAOCBvPYwH/3NaeQLhqlqo4xrPD39RWf9pabPCc13GHt+l5zzqtBe+v5J/LyqSqG9yvYYDX9FtqO79lLe369bTxTankns440NyBiEuo+Z9XLqyOY29tU66qU3WP0mT/qgymFCC+9UfqSGNE7Wt3M8paizWWgfJaucdaCtT2jtFntbIc3DVH2vQJcWyVA8zIwWOQkpcZTOuPQboyb7hq1J6WEWmOxFdmQiQqsP7XbW+iSTqBorsXJ7mHrkJOjL3RovqERO9HiI8Ddd4ig6qr+pv6cad8iKnORqm9fveMggeIqfJB8PkRPQD3CHCQAAAHgAF0wAAADAA3ldkq38zSryGwFqvmaq2F5svuSsNz4wVmjxL3A94s/lfxTaspe5RNp21jih3d50rrMOL/9QaMcpFcUr3p0stOikdmfda8lSbrKe9/fZspeE9ov0eGfd3ZAWWvAJfs/4aFmSjTZzycgMyVJn8x6OYRTGNwttQx+XZM0OrQuQEtEIdsiYTsLmYwvKedUCs1frrqNOOenTSrJK2aszqcVRDD6HHWlZko1GuFy7Oy3jNm5dgEKmGivJPckkqUVO1LKrDOIQBVy6AKmRE7cuQDpumpGjVJhr+8daTmlwugC54fKe/Y6c5EnpEZGT/AF3mAAAAIAHcMEEAAAAPIALJgAAAOCBvPYwzTEjyfSF6KprnhHbP7f2S8664ndvC632Jf6OsD4lPcVMB7eL232ObCvX9vpIZz2qfYnQ+mx+n9hS6av929fectZvJKTWNo4fTw/J6ShmlOMUVaNbhWbv4cfdJ9UIraCZfTWzRLaOo92KV2hJL/Kjbo6c2F3dQtuRLnXWwQ55zrptdu8CXS5t83qkUeMn9gqTfdJTDCvmWmdCi4cofmNXSm+3xz+zpozUin0cxenV2ubJWInub6o+pfx+GVTiLxnto/sUDzNl6x6m0hpP00yX6Eh/PEzdx5ORk362zTvI29gdFJ8BDAq4wwQAAAA8gAsmAAAA4IG8Lsmuv7GAzEiY/lIiByX/8b/OdNZGgcw6/HzEX5z1ySuvElrlMVyO+/7Up4T2m1+f76z9DaOF9kxvk7OuWibLmV/4Fnch+knzGULrUJIr5T7ZBcisLHfWM2pkjGW10lGnq07Wj0o+4C49Vnmp0MK7le9HWqZgcwc/t7Jni9C2Jjm64u+IC63L4vJcsDv34Gm9JCsGT/fJX8Ow0iGoJxEUWoEyeLorHdI0Lhd3aSXZmgAPB9cnmbhHTtRpJVpJVsRKcg+elsVvWZLNjpy4dQHa/8HT/Ro6TTT0ZdeDoQyKLkAHPbjDBAAAADww4BfMefPm0bRp0ygWi1FlZSWdf/75tG7dOvEc27Zpzpw5VFtbS5FIhGbOnElr164d6EMBAAAABowBv2AuXryYrr32WnrzzTdp0aJFlE6n6YwzzqCeHu4ec+edd9L8+fPp7rvvpmXLllF1dTWdfvrp1NXl0ioGAAAAOIAMuIf53HPPiccPPPAAVVZW0ooVK+jkk08m27ZpwYIFdNttt9EFF1xAREQLFy6kqqoqeuSRR+jqq6/2vK9nP3UvxWImnbPuIrG94Mnlznrrt6YLrd1SWrn9Xnp8W87i7w8XF+4W2sPLeZrI7n87Qmi/2nSKs46sbRLa+AD7Za+8L9v0lYxjX63bkt5gchT7hqfGnhXaapv331cn2+b5d3M0pm9MudAiu5W2eREZcWlvZw+1PCEjNZvifCxGd6/Q9qpt87pye5gB2W1PYPZqLecUD7M3Lj3MkOKx6G3zokqspDsjfcqwEkfpSBXk1HQPM6JMOdHb5slYiRabUaMjJAm4aG5t89zb3OVojZfzFf9C2zw30DZvQEHbvE8Wg+5hdnR0EBFRWVkZERE1NTVRc3MznXEG/wFMKBSiGTNm0JIlS/b5HolEgjo7O8U/AAAAYCgZ1Aumbdt000030UknnUQTJ04kIqLm5o/nMFZVVYnnVlVVOZrOvHnzqLi42PlXV1c3mIcNAAAAZDGosZLrrruO3nnnHXr99dezNEOr+di2nbXtH9x666100003OY87Ozuprq6OWjJB6s2YFP9xrXh+wWguq33usteE9rUPuXxb9tf3hTbiL/y6TWlZeswo/uruGXI2RWAFd9up79oktLQSKih6R5YJz7pimbNeqZUXO+r58dGhdqGZYdbKhkvNbuPHvdWyC1BkjxI3iBXK17Uqx6ZFFjb3cknW7pHnpTnN3YQCXfK89KpdgLpdugD15e4ClErokRN+bndSK7safK579MiJUq7ttWSZV+0CpA+XVmMlg9EFSGeguwC5lV3RBQiA/WPQLpjXX389PfXUU/Tqq6/SiBEjnO3V1dVE9PGdZk0N/w+9paUl667zH4RCIQppo6oAAACAoWTAS7K2bdN1111HTzzxBL300ktUX18v9Pr6eqqurqZFixY525LJJC1evJhOOOGEgT4cAAAAYEAY8DvMa6+9lh555BH685//TLFYzPEli4uLKRKJkGEYNHv2bJo7dy41NjZSY2MjzZ07l6LRKF166aUDfTgAAADAgDDgF8x77rmHiIhmzpwptj/wwAN01VVXERHRzTffTH19fTRr1ixqa2uj6dOn0/PPP0+xWGy/9vXlv1xDZjhMY559U2z/8PbjnfXTlX8S2uT7PuWsq/pWCO2OkU8761u2nC803xg+tqumyL/mfWEOv6evqlJobyXY9yp/R8Y1zile7az/1D5FaJ0NvK7U2+YNK3PWU6u2Cm1zN/uGPTWygFD9huI/lhQJLdSau23e9m72KUt6dwqtOV3irH3d8vOpbfMCvdLbUn0vX69b2zwZ5QgoWm9Sn3LCnqLeNi9s8HnRPcyqQIez1n1KNXKS1GIlbm3z3GIlfkNpjecyyUTHTVO9SvGemqco2ub1N3Yx1C3gPkneZ7/jNmibdzAw4BdM2/7nvxiGYdCcOXNozpw5A717AAAAYFBAL1kAAADAA3k9raTx7q3kN0PUc840sf3mC5501g92ym43tU/yZJOuzxwltNH+N5z1e8/LrjwFn+I752+UPSS0pSvHOOveo0cK7eE9XB4OfyDLmUcFuYvMrC3jhZZq4M4/4s/2iShTzR2KTixaKrRNaf6L5L5q+brAXm63ky6XsZKQMqPa8MuyZGsnl4SLk3KA9PYkH4vRI7sVdSgRjYA2yUSN2/j7KCdGQusCpERO4lklWf4Z9aaDmqaUZDO5tfZMVGghly5AfjVWktUFiLWkVq6V00okPsNbpx9dyxUrcRs67VYm7HcXoKEu8x7CXYDA0IM7TAAAAMADuGACAAAAHsAFEwAAAPBAXnuYdl+cbMOiwn/fJrZ/tZh70o598BtCq9/Fnt+Oi6qF9mh3hbMe+axs8L7+eva9hply0kd6C+9/1xWyz+2WdexNHrZjtdAKTW5x17uuRGhHHsde6/aMbEfXO4I9xSlhGSt52BzFD2qkp2i08WeKj5OTWsKt7KuZBfLzJTs4omGn5XSUHXE+bqNHmpHtFr9PoEe+Lm7zY39vbq/J15d7kkkymbttXk9K9yl5fz0uk0ziad0XVaMjcn9qrCSjGV8BxcO0NC0oNInP4yQTHSNH2zw3v9Hst8fXz7Z5YEDBJJOhB3eYAAAAgAdwwQQAAAA8kNcl2U1XjyNfOEzvNt4ttn9/90RnfdivdwktOYOjJP8zfaHQrn7zCmc9ZuU7Qvva5G5nvahPliyNIJf/wtP2Cs332jDlifL7yZ4MxzxK1gmJTj33A2f9Zny40LpG8I9tlF/WZcwCjkWMqmwVmtXJE1d6y2UMonAHlxeNQhk58XXk/jXZ3stdgKhPToluyXB3JF+PNsnE8hYr8cW1z6fU/DIJrQuQovWmcncB6svomho5keXa8gCfM7cuQHq5NujaBYiPRZ9konYIcusCpE8yyVWdc59W4j06YtEAdKo52CeZHAyfAbiCO0wAAADAA7hgAgAAAB7ABRMAAADwQF57mD+46GGKxnw0v61RbP/D72Y66+EfvSW0j77FrfJOjcjGZBVPs3/lK5bTPL5e+qqzPn/tl4QWG8ce5tcPe01oj/3yLGftr6sV2pI4x1hK10kj71PR9c76nt0zhdZTx16QGk0hIjLLSpz10aUybvOu4gf2VUjDpWwtt7yzi6WHGWxXnquZW3t6OeIyLC49091pPodmr+ZhKnZWoE96Wymbfy4+mYwRk0xI9zAVLbttHr9nj1vbPG2SSVDESvT98Xvq/mZAnUiimVuqT5nSNJ+Ru22e6dIaL9ckE93DVH3RbJ9SeY8hiJwMCAeDb4hJJnkD7jABAAAAD+CCCQAAAHggr0uyJ0faqChi0vcWXCW2j3r8I2fd9Vk5mPmHpzzurO/rkCXS0heVSSanyGklpUp3n7ZXZYeg+DQuqXwhtl5of3lvsrPumVgjtD/vPcZZBzY2C21sgGscS7bXC82q4zqlWr4kIspUcMzjmEI56Ppdi7sQxStkCc/fmnuSSVBpeqRGaIiI2rv4vJRpXYBaUmpJVtZWu5RJJv5eeSxqadAnZ1ILsiaZKF2AEim/pvFan2QSUMquCUvvHuRtkok+XNptkokcIK3FZlzKcz6P00XUcq3btBLXyIkL/Z5k4vqmbhommYBPBrjDBAAAADyACyYAAADgAVwwAQAAAA/ktYd52sovkS8aouH3LRfbLZ8SL/h/bUK7LMat6xqeuFpojbs4grLt7JFCe66P/avhi+X0kA1XsB9X7isQWnr7Tme951L5njuaxjjr+l3vCi1qss/W2yQjLo1H84SSXRkZR4lXsad4RHCH0MhQ9l8hzUGjk1v/JcaWCS3UrnhiIdk6LtXNx6lPMmlOKMedSApNnWTi75U+rJhk0ufi6SX0tnn8c09pk0zU0Ecio/uUvL++jBY5cZlkosZKBmqSid91Wsn+TzLpr9/oatUNkE+JSSaDByaZDA64wwQAAAA8gAsmAAAA4IG8LslWL/CT3x8gc6yMXeyZxiXFv076idCe7uXpIWMelWVJ3xHjnPVNxy8S2g83nOOsS1bJ6Mhp87n+8U5Sa02jED9KlnL965XyrSXLkt0Wv0/RRvm95vhTm5z1e0k5CLq7hn+kI/yyRGpGuAxaWS4HZNs9fGx9ZTIGEW7nYzMKZLTC7Mr9K7Q7zvEUOy7PS7vF7+OLy+NMKKU6vdOP2HdSe6xOMknpkROly1Eqd1cefZKJjJxIrdjH58ytC5BervW7dQEyck8yEZ1+tGklqqZOMtErc3K49MBETsQkk35HQDDJBHzywR0mAAAA4AFcMAEAAAAP4IIJAAAAeCCvPUxj2VoyjAB98NvJYvvR9R866x5LeiPX//1SZ93491VC2/rt453110s+FNq9D7GHWRTfJLRrKt9w1vftniE0fy1PR/lM4/tCW/EXPm5fqfQi1ykeXHGTnPRxfMEGZ720d4zQeqvZLFHb+RERGTH2FBtLdgutpZf9uESZNFyKN/H+7ULpYQa6cpsze/p4fwXxFqHtTbPm0yaZxBUPzh/Xp22o/qY+6YPPmZ3MPckkkdZjJewb6h6m2hovrnmY5X5+nd4aT/UwszQ1VmJ7j5Wo3qdOrmklbq323CaZ6J6i9D5zvuXgtLjrLweDb3gwTDI5iMAdJgAAAOABXDABAAAAD+R1SbbjomnkC4bp76f8WGwvVrrkTHtLdvMZ+RiXx/zD5bSS6s9wB53WjIycDH+Fp3n4xssy6JTQCmf9hXeOFFr9BF5fMuwvQvtw/WHO2h4lJ5m81svTUqJNHUKbEOTuRQu2NggtXqMMXza070Ml3HnniMImIe1Kc8QlXibLQP4OPhdWkSzzipKsKUuP7X083DqalGXX1gzvz+iT+ZAei4/bn9BLg/zYp8VKVIykFishPra4PslEec94Rp9ywucza5KJ0gWoxwrl1Czte6kaHUlmabkjJ3IiiUR9ppxWIku1quba6WeoS6tDXebFMOuh4yA6L7jDBAAAADyACyYAAADgAVwwAQAAAA/ktYc59RurKFgYoK0Z6R9tTvP3gMr7pOcWeultZ739G1OF9uCY+c76v3aeKTTfqnXOuvkqGWPpsHhiSNlSGT3YPYkL+FND0nkyN/Ekk/bTxgrthd2H84OdMgJS5ePPtH5npdAi1Tx1pNeSJl+6nKMch4e3C+0l4v2nyqTvZXTz50vVyfhLoEvxy4Lys/f2sIdpZ+Rn35OK8ftrk0x6lVZyvj55LCmb38eUNrM85qQeOeHHqZQeAeF1XIuVBCm3h6m2zUvZWtzGLVZiqLESzcM01dZ43iMnueIjpqtP2b/WeK6WYj+no3ySsA/yNn2YZNJ/cIcJAAAAeAAXTAAAAMADeV2SvbNmJRXFTDrsd9eL7ZkSLpWN/ZscLm0O40kmoz//kdAmBbmEuPjFSUKrTy511t0z5NSRJ7tHOeuKpXIKyPobuVzsJ1may7RyPKRtnPzu0ryFYyaN7bIjUcDg9zG2yJJz4/Fc5t2VkaXOeAXHbcYE9gpNjYSYpdpw6W7+vMniCqEFlZKsEZal8Uy38uulTWPZk+DysD5cusvin4M/Ll+XUkqkvkTu0pmplWTV4dLptPw5BJVaoT5cWi2f9llyuHRQRE68D5dWS6tJ7XfCp04dyZpk4q3Tj/qs/Sm7eu3m4zrJpL8REAyXBnkA7jABAAAAD+CCCQAAAHgAF0wAAADAA3ntYd6wfRoFC4M0bv4WsT1dxxNCfEeME9ruY9nDfLrhJ0J7uneYsx71TJ/QzAmNzvr6Sa8I7d6NJzvr0nWy5dyp49icWZvSerkpretS46UvGlqvxBRs6f10W3FnXbhNmj+TS7i934aUjID0lrNfVuWTHpGp+I8VpV1Cs3v5XMSLpecWbmevzohIP9Xslc9VaUvyc+2kPC/tFn92MyE9zIQ6rcQlVmKmtMeKSWalTE1T3j+te5i8v2x/U42VyM8aVTIvuuYaK3FpjWeqmmYHqrESdeqIHjexFK2/8ZD9QW1l2G8O8pjHQfEZDhFwhwkAAAB4ABdMAAAAwAN5XZJde8+R5AuEqbR3nRTefMdZfvDz44RUNZYHGQe0WsjNb3/eWde99Z7Qmv8fdwX6crHc3y+X8XDp4l45ePqycj6W37dPE5qvgkvAJ9RvFNoHfzuCn1dUJLTNaS5RxbalhTY5uslZvx0fKbS+Cv68xWZYaEYBTw8ZVdQmtPY+LgEni+U5K9qi7D8i39Pfk7vW1Brn/UWSMuLSnlFKsn3y84nh0lqsRAyXTgzMcOmAErXI6vSjRFz6O1xaL7sO9HBpt9IqhkvnORguPeTgDhMAAADwAC6YAAAAgAdwwQQAAAA8kNceZuwPy8lvBKjpv44X2+te4IjGgrMfFNr4IE/+uHbLuUKLPMNeoaFP3pjBU0DU1nRERNVLOcPgH14rtGND3FLv2tWy3d7wBj79F5Q/LrRfbhyj7EC2o1udGOGso9tkHEX9fI+2TBdavIK9Jv0zGDH2FA8rkC0Dlym+XrJYSOTv5s9uFbp4mKbcX2ecYyxhPVaiepgJmQ+JK76eL6l7aUqcQouVCNKav6kYWsmstnl8zuJarCQo2t/pPqUaOcndbi+rbZ6LvymiI5pmCI3x6V6kco76O1nE3accBF+tv35jf4/lYPA384U8O9e4wwQAAAA8gAsmAAAA4IG8Lsna0yeS7Q/THZf/Vmyf3XCxsz4n2i20NPHEiXefOFxodc9zx6CekycI7cYjn3HWT3bLoc0Fq3kYc/fkEUILGXyKrXdkPbN9HJeMTgjvEtr9Wzlq0TdW7u/vndx1yLezVWi1Pi4Nvr+nSmhUwd1n9GkQmWKlJKsdyzKby8zJYq1DUDdHTtKl2hDlHl4bPlmy7OlTJptow6Xb0nwslNRLsvw+vnjueIOpNVVSMVIuk0wy8jukOlw66TJAWo+cqOXaXktOcQmY/Dq3sqte5hVdgOzcr/OynWgf0RHP5dr+lToHZbj0EJf0+j1cOs9Kj2Df4A4TAAAA8AAumAAAAIAHcMEEAAAAPJDXHuae2QnyRYk+HZE+3hMn3+Osr98xQ2gFyoiLuse3CS29lR9vuXm40C4v4qjFicu/LLTq7e876+ZrRgltfYo9vvJ3pFe361j+vlLpKxCa1cwt/DrOlMeybBe3vCvfKye1FCot79qbY0KrquOWd53KxBMiolQZv64h2EIS9jAzJbJVndHL75MaKT3aQLfiiWkxnVQfP7Z1DzPFXqihxUq6LPagfUnpp6bsjKJRTsyk3jaPH6dSWjxEWWdPMuH9ZbXNc4mOeNXcppVY5K1tXta0EqHRgAOrLr+x8QN0BXeYAAAAgAdwwQQAAAA8kNcl2eeP/h0VxUyavuwrYvsb037D64XHCK1PaZozatMSofkOq3fWV578mtDUzjj2q3IwsxnlEmLZVFnOfLyT9x97d7fQ2r7EQ5R7LVlDtOJc6uysFxKlt5Xw/uLrKRehZlkGHTuJj61ZVkEpXsa/CsN9Mopj+FkLFcmpzbZako1p5cxepSQbltEKu095rjYguz2Ve7h0jxLR8GnDpVO2GitxmdKRzh0rsTLyM6jl2qSldQFym2TiMlxaLbu6TzLRIy77nkhCRGQqkRB1uPT+xEPEcOl+TiRxjZz0t0OQ9jo9EgXAUDHod5jz5s0jwzBo9uzZzjbbtmnOnDlUW1tLkUiEZs6cSWvXrh3sQwEAAAD6zaBeMJctW0b33XcfTZoke6jeeeedNH/+fLr77rtp2bJlVF1dTaeffjp1dXUN5uEAAAAA/WbQLpjd3d102WWX0f3330+lpVzCtG2bFixYQLfddhtdcMEFNHHiRFq4cCH19vbSI488MliHAwAAAPxLDJqHee2119I555xDp512Gv3whz90tjc1NVFzczOdccYZzrZQKEQzZsygJUuW0NVXX+15H4t6h1HU56PaO+THuHDeBc665iGt1Du82llmjpN3vjunFjrrbw37ndAe6+KWd7WLO4RmT2hw1tc1PCu0O97nz1m7ZaPQThvFftW7Wrs21Tf0NUhPMfCOEhfRDKUOq89ZR3dKX+iIwp3OemO6TGjxMv7uVGbK71FGiH3D8qIeodmK15qIyddFd/PnM8JykomvN/d3tfak0mIvKT3TLov9TUOPlSg+nlusxNAmmZiKSWalNN9QnWSS0f1G3n9a9zddJplETf5Mli33p8ZA3DS3yEmu1xARZRSf0rVtXk7lX2mNJx+r02X6TX8903zhYPgMBxGDcsF89NFHaeXKlbRs2bIsrbm5mYiIqqpkn9OqqiravHnzPt8vkUhQIsH/k+ns7BzAowUAAAD+OQNekt26dSvdcMMN9NBDD1FYu6tQMbSvm7ZtZ237B/PmzaPi4mLnX11d3YAeMwAAAPDPGPA7zBUrVlBLSwtNmTLF2ZbJZOjVV1+lu+++m9atW0dEH99p1tTUOM9paWnJuuv8B7feeivddNNNzuPOzk6qq6ujH/7uIvKFwlT31hvi+a2/5sHJZfS+0DJr1znrD+cfJ7Rh4zj2kdHKRXe+d6azHvHOBqG1fI0/67kFsnvQf79T4qzthCwvnl/yjrN+uvNooZnDuGQ6dcRWoa1/mqesmIWFQtumNOIp1LIjh4d5qsq6uBx0HS/jLyuFpoyAGEpsZkSsXWjtcf5MqZj8whPYpBxMKCg0X1/uWlNXUhkunZYl4C6Lv4SZcdl1KGmrJVm9FKlETrTyt8/g7422HjlRYyVapx81yqHHSkwlhhG3ZLyn3O81VqKdT5M1S2vJkqvTj98liuJWWt2vKSdqLMgljuLKUA+lduNgKIMO9Tk7RBjwC+app55Ka9asEdu+/OUv0/jx4+mWW26hhoYGqq6upkWLFtHkyZOJiCiZTNLixYvpjjvu2Od7hkIhCoVC+9QAAACAoWDAL5ixWIwmTpwothUUFNCwYcOc7bNnz6a5c+dSY2MjNTY20ty5cykajdKll1460IcDAAAADAgHpNPPzTffTH19fTRr1ixqa2uj6dOn0/PPP0+xWOyfvxgAAAA4AAzJBfOVV14Rjw3DoDlz5tCcOXP+pfcd9T/vkd8I0t7LpRdZ+vuVznqn4i8SEdW8stdZzz5TRkCOiTQ567m7jxeab7GcxKHSdixnGAoNWTouf4c9HF9FhdAmh9if+9Z7RwitYgT7XmeU/U1oO7eNcdZmuYyHfJBkHzjSLCeSjAnwZ39yrzwvyVL2PNQ2gERERgFHOUZF5XSUNsXzS0k7lXw9nN+wovIPwPy9ilGk/bFXZ1zxMFPatJIMH4uZlB5mQrFtzJTupSlxCi1WIkjLv4PzKYZWOiO1oOIPZrXNc4mVyLZ53ieZiPZ3WbGSfWtZfmOO13ys5W6Np+LeGi+3Nii+2sHgN4J98wn82aL5OgAAAOABXDABAAAAD+T1tBKjKEaGGaLjZ8sGCRteqnTWx165SmiLKyc76+tL9UYJ/P3hij/JMu/Yxe3O2p7UKLTzjuR4yIqkjHIUreEyaGqcHARdbHJ5sWO9LK1G6rl8dVxEHuej27jTUKpWTk5Z1csDrP0tssFDlY9LiOvbZXk4XZa7TmkVcqxkZGiv0Fbbw/hYimTJzexVS7IyWuHnhkRk+GTJsi/BERQ7LcuuHUpJllJSiyulTz1WosYb3EqyhhY5USeZpLROP+q3zWTG+7QSn1KajGvdfHxKmVcvu/pNl+HSObrmDFQ3Hz1mNdD0twTs/qZuWj8/z2CUCT+BpUewb3CHCQAAAHgAF0wAAADAA7hgAgAAAB7Iaw9z3fXDyYyE6emav4rtE66a5ayfGi6175zHUYu/x3O37Rr1jDS67HfXO+ud1x8rtJ+Wv+qsf9J8htDszdwqb++nJwutLdPrrIvXaVNH6vm7TL1f68m7p9VZdk8uF9LKNqXPbmub0IpNfp9de2VMpqCMTcVeS476yBTz6+oC0sMkYg8zHZPn0+zlc52qiArN16dEGPzy1zCZYL/TtqTX1JXhYzGS8mfUo8QwzKzWeN5iJYbWGs+nGGhpLXISUJ6qx0p8iueXtvTXqf5mVNMUn1L3NxUfVp9kIvxNpW2e7mGqPyE3f9N0jY54b5sntNxveVBgH+STU+yD4DP8q+AOEwAAAPAALpgAAACAB/K6JPvQ2fdQYcykq7fNFNuvvHiRs36uT5a8fli11Fkf9fevCK2ogEuIw16Xg6dtJfpgz5ClziOCHHV4ZfXhQhsb5/21HSUjJ8sSXBYtWye78nx4MZcl9c47VgfHRbrq5Hee1t1cIh3d3SI09X3s3bIj0fAjeVJLh1aSTRbzsQz3twtN/M1/TKt1Jvh9UgVa7IKr0WQE5SSTTJ/yeS15zrrSSnk6K1bCx+nLGi7N7+NWktUnmaixkkxaL7sq72/lnjqS0KaVuHUBUgdB651+1IkkeqxEjapYlLskK/eVu1zb77LrYERA9uN16lQaAAYa3GECAAAAHsAFEwAAAPAALpgAAACAB/Lawyz1pSjmM+mdnx0ltv/PT+911g1/vFpoz31uvrMu/730N3uqebyYbcupHHQkt8O75XA55WRPhqeOlC/VfK5h3PJu8oQmoT3VdoyzDn4k/cbq0ezVqfETItkurmeE5tk0R/f5PCLp74Rb5Hel0TGOi+zKSM8tUcyfqcIn/U3Dz8+NFibkccaVWEmBFoPoU447KPdnJOQ5VGlPsl9sa7GSXot9WVPzMC0lVuJLuXhw0jIlUzHJLCt35ERvm6fGSlJaBMQk1aeUr4uafH6zfEpSPUz9Pfc9rURvmZdRHrp5kVn+pnL+dLvRIm++odv+dNTpMv1vY3dwxzzA0IM7TAAAAMADuGACAAAAHsjrkuzZL88iMxKmsb97U2z/5X9yt5tx93UI7crGK5x1yTNrhFZUy8OXk8fLgc4tU7hE+oXCZqH9b8d4Z12+VEZO0mP5WC6rflJo3337c856VPP7Qjulmktza1KydGwEOIYRresSmr1M6eBjynJfp8Ul0vAeWa4aF93lrLek5QSURDHXr4q19zSUcmp5YY/Q7DiXaFMFsgZWsItrn0ZIRlzMvtz1su608ty0LAH3qCXZlKytpjwOkHbTbL3Tj1LXS2V181GHS8v/zESsRNN8Jv+M9G4+AaWbj1unHxU1ppKt5e6G1F/2p+wqX/cv7/rQA+dsyMEdJgAAAOABXDABAAAAD+CCCQAAAHggrz3McQs6yO+LU+qko8X2u/7Ant+od5cILf374/mBT0Y5Mh9y7GPz16uFVjiOJ4SkbOkX/e+GE5111QYZHdl7JUdHPh2R3qe1vtBZ6xGQmTH2NF/umiA0s4R9yklVO4S2obmIn1cgvc9m5bCje6S31RDic/FhQn72ZAmbJVFDtrEzIuztVkaln9qpxD50D9OnxkpC8j19idzmTFeSfcpwWnqmPRa/j6F5mEkxrUT37vhYsqeV8HdKW9NMl1iJGufQ2+a5xUrUlnpJvW1ejujIx8eptMZTxkqo7fSIvE8r2Z/IidvrhC+a1YrPYxs7N6+uv5GT/nIw+IZDfc4OInCHCQAAAHgAF0wAAADAA3ldkrW2bCfLCNDeH48W28dcz11res+cKrSKp9Y56/ZzZHSk9O887PmsTy8X2klFPEB6YWej0BJLuZuPnVwntLajuOxU6pMl0pIPeO0rKhLa0aF2Zz1341ihRaq4DHpi6d+FtqP5MGetlm6JiDam+TjDLTKSMdrP5+z59olCSxZzCUefnGJEuPNOrVZy7lDayqQKhUS+Pi5B22GtJKvGSrS8QU+SnxtOyQxIl8XHYiRkSTahVKF8/YyVkBYr8amxEm2SSVDESnRNiYdklVaVIdHa91lV04dL5+z0o5dI3boAqe+X9Tql089gREdQJgT7wwEqjeMOEwAAAPAALpgAAACAB3DBBAAAADyQ1x5m81eOJl8oTG8cs0Bsv2D7Cc5610+ljzfypW5n3XmhjEEkC7iN3cKqx4RWbLJveMSr5wttxDJuY+cfVSe08RO2Outt6W6hlazjx/bIWqFV+gqc9eZNFUIbPYLX0yIbhfbXnRy1yFTKz74uzvsI7JWRjCrF2Puos1xoqeJ9t10jIrIL2TccHpJtAd+3ePpLOio9Kl8f78+KyGklPsVeNXzS/+tL8nPtjIwldGf4Z2SkZEwnqXh+eqxEnYyRo8Pcx++Z0WIlyvfNtKV7ipRbU7xIPXKixkrUVn+6liItcqL6my4+pYqbF+lqN7r6my4vHGpcP4Sb1t/pKP172ZC/J+g3uMMEAAAAPIALJgAAAOCBvC7JXvnlv1G40E9/7ZUly64LOEry9LSfCO3Lp9/orBdO/qXQrrC/7KyjhiwT9tpcdi1cLOMh4bc/ctadJ9YL7dra3zvrv3aPE5qviWMYnSc3CE3tJhRtksfSNYJLRo1+mYMw9/B0lp5Jssy7tpsfG22dQis2Oa6xvUOWcn3FSscercuRVcBlw9pAO0mUkmyBLHMZfXw+0xUyc+LvU3cuS4+JBP/K2hl5LL2i048sySaUrjnZJVlL0Sg3WV2A+HEmo0dAeJ01rUQJcOidftQh0WrHHiKt7KpPMjH2PckkeyJJ7siJ3Fd/oyODXwKWmpejOvDYGGZ9UIA7TAAAAMADuGACAAAAHsAFEwAAAPBAXnuYXyveTEUxk4781XVie+XXeIJHgSkNgi0XsddzdFB+/DuPetxZ39Um2+aFFHOr+rVWoWV28aSPXceOEdppUW63d/7aLwmtYA9PNmkbJ9vtbUuzkVfcJOMTrYfz9xy93Z7V1u6se6pHCm1de6WzjnXtElpU8TB72iJCK6tkv1P1comI0jF+XbW/nSQcsbEKpN9oJPh9MlH5c/DFlZiC5mGmk8pzbXleOtLKcWv+Ztzm15kp+TrVlzWk9SkwXTTdw/QcK3GZVpKytfOixDf0tnmq5yhb4+WeCKL7lG6TTKSW8y3BIYp9iPxO4A4TAAAA8AAumAAAAIAH8roke8H6s8lfEKLRd70rtj98zXPO+qw1VwrtrhMfcdY/aZUxj1uGbXDW171witB8RVxCHPP+GqGZMY5P1E3dLrRypWNP87uVQhtDXJLtGx8X2rLEcGcd2yi78uw8g6McGa0safX2OuvealknadvLcZGCvs2UC1+rjLHUjOGOSB2WLHWmCvlXqMInj5NMLjf6CrV6Zpzb+aQj8nubXy3JBuWx2HGlhGnLsmFPWumMk5T5kLjN75M1QFrt9JN2iTDoA6SV75tZsRJlrXfzUUuraV3L0bGHSJZrs6aV5Igt+LJKq95iJf2Oh7gMie53BGSAXqf/twLA/oI7TAAAAMADuGACAAAAHsjrkmz651VEgTAFi2UZqFmpGgbuHya0c37Jpc/ZT5wmtLMu5FLryKflvrpr+C8wzbBsip2ZyF16Zo18Umg7lYbrw97ROsWUc5PzY8dsEtqiNh7i7N+6W2jDa/kvY9usPqGpZcq+Gu0vU3crx62XVpW/FA21yuMcWcBN1Xdn5LDnZIy/c5Vof0aq/oVrJCoHVtvK8Ge3kiwF5P6MZO7veD1pfq6d1v9KVi3JamVs5Zy5dfrR/+DUVGp+dkYvnypdgCy9K4/6V7L6X9e6/AWtqfxlsT54mtRSrtLpJ2tItMsAaeXh/nQBUs9fv6un+9FZSG2W3/9G6ei8A/Yf3GECAAAAHsAFEwAAAPAALpgAAACAB/Lawwy+sJL8RoDe//lxYvtnl8xy1g1/Xi60h3/EnuaY38sB0t+a8kVnXbD4A6EVDK9y1unJY4XWMoU9xbOie4T2u67DnHXZOx1Cs0ZXO+vzy/8qtB+uPdtZj9izQWjTK7iz0IepsNAMP/9IQ9W9UlsdUx5Io0bt4BNulf5OfYQ91OZMkdCSMX6fYlN6bmokpDQqvVZbiX2kIvJYoruVKIIWKzETuQ2mbjVWkpaeqTqM2UhrnX5ErCTn27t2AbKzYiV8nClL13LHSoJqpx9tyonPZP/dcomVuE0rka/xHrPI2P30ChX2x6eUr/uXd33ogXM2KOAOEwAAAPAALpgAAACAB/K6JBs/awr5A2H60+cWiO03fZlLsr4G2YD8uy9PcdZjly8VWvNzJzjr4b07hWZ/8KGz3v6d44WWmMjlxoAhS2yPbD/WWQc/2iq09s9xg/eTIlKLN3H51E7JhucnxDY66zf7ZLN3tetQY6WMo2zfzYOazYhssL5HaVYebpOls7oAN5vfmpQxnWQR137Chvx1MpT4TVlYlofjSWWAdFSLSMSVSMh+lGR7UhwrCWW0/YlYiYycJNVYSVqPWijDpbMGSPP3TT1WYip1xFRG/k6ocY6EVnZVYyWWS6efpEvTdrfm65bLAGm35usqbqXV/XmdKPP2Ox7ipv3rZeT9AmXQgx7cYQIAAAAewAUTAAAA8AAumAAAAIAH8trDLPrmNgoUBLNasvleXumsP5wn/cYxj3HcwHdYvdDqntnrrDNTJwjNfIc9zJIZzUKbUcXaGwnpLW16t9ZZH9a1RWht49j0GOEvFFqsib/LGCHZiu/oEA/IfqxlmtBoGMc+Jpesl/vbM4rfMyb3tz3Dj0Otsj9cXYDPy6reUUJLKW8TMqTfaIQ58lIVaRPaZsUzTcsZ2MLDtDUP06d6mFreIJ7mX+dgWv5OiFhJSm8LyOv+xkoondvAyli696nESrR4iM9luLSq6QOkxZQT5T0DmoeZ8TitRG+bJ7R++pv7g0WYLHJAGGrfdzAYRC8Zd5gAAACAB3DBBAAAADyQ1yXZx8a8QEUxk+qfnS22j5vMMY//+LfHhfa72+qc9Zabpwtt+I+WOOvNP5Cl3Do/d/f5z8N+J7RGpWR569bPCa3sbaUEpkQ+iIiMcTzJJGHLMmjxRn7sqygX2gg/lxffba6RWiWX8SZH5ZDoJWr5tlgey6Yk7yPYJodZV/j4fG7uLRNaKuZSOgtxzKMi2C2kTRn+1cvIZkXkSygl2bAWK1ETNob8vteX5OfGMrLs2mvxsWSVZNUyZVqPWiiRE/kyiV52Vd4znXEbIJ27C1DWkGgxyUSPoyidftRpJS7dfPTSqlquzYqAKGu94pVxKd+quHXsce3mMxhlwn6PVRmE+AvIG3CHCQAAAHgAF0wAAADAA7hgAgAAAB7Iaw/zZ60NFE4G6PA728X2929kn+2qohah/aFysrOefv47Qtv5QKWznnra+0JbmeSYyekROXnDZ3C2Yvmqw4Q2do0yEaVhhNA+Xc9TSN5PSq8puoknm6TqpIepxjcSW2U8pK+aPZZxAfnZA3t7nHW6XL7uowRPYzE7ZFu5MuVr1bauEqFZsdzGnhVlc7Im2C5Fm1vspaPSFzL62L+1onqsRHmeKY2hREr5dbbke/Zm1EkmeqxE8fyyPExlcopb5ERvjad8F81YuhepHIqlt7jjnWTHSvjY4i5xFLfoiND6GR1xI9v7HNyYgluMpd9TTvLFb8yX4zyIGJQ7zO3bt9Pll19Ow4YNo2g0SkcffTStWLHC0W3bpjlz5lBtbS1FIhGaOXMmrV27djAOBQAAABgQBvyC2dbWRieeeCIFAgF69tln6b333qOf/vSnVFJS4jznzjvvpPnz59Pdd99Ny5Yto+rqajr99NOpq6sr9xsDAAAAB5ABL8necccdVFdXRw888ICzbfTo0c7atm1asGAB3XbbbXTBBRcQEdHChQupqqqKHnnkEbr66qs97+uJ/z2FfMEwVW1eJbY/cPoTzvp7u48Q2o4LeLrHIyN+KrTPnHqjs753xE+EdvmnSp11myVLsnFl6kLlW1pp7kOeQtJ67uFCu6GUj/uZrklCox27nGXnZPk6NYJSsE1+5+nmmdRU55ea0dbJxzy2VGgburkcTR0yAhIzOZKxt6tAaIEY10hTtix1quXUCn8nSVxKsspwaatUTlVRS7LkkyXLVJJ/nW23WIlbSTallRTFJBPKiZE1yYQfZ/Th0spTszr9uEZOcncBMnN0+vGRPq0k93DpzABMMjFdoyP96xB0sFcebbfy98H+4fOMAb/DfOqpp2jq1Kn0xS9+kSorK2ny5Ml0//33O3pTUxM1NzfTGWec4WwLhUI0Y8YMWrJkyb7eEgAAADjgDPgFc+PGjXTPPfdQY2Mj/e1vf6NrrrmGvvnNb9KDDz5IRETNzR/3Ya2qqhKvq6qqcjSdRCJBnZ2d4h8AAAAwlAx4SdayLJo6dSrNnTuXiIgmT55Ma9eupXvuuYeuuOIK53mG9idstm1nbfsH8+bNo+9///sDfagAAACAZwb8gllTU0MTJshJH4cffjg9/vjHLeqqqz822Zqbm6mmhtu6tbS0ZN11/oNbb72VbrrpJudxZ2cn1dXVUcXC1eQ3ArRj1lTx/BPDf3fW1//PDKEN/wK3i+uypJe1+xw2yGp80jv77pi/Out726YILWSy51a2Yq/QMu0cD9k7SX4hmB7iCR7f33Cu0Io6NjrrznpZCNiW5uOMbZUe1d6JvI9CU/acs7rYm+wtlx7Y5i72NIt65J2+GmOJd8jJKeXVfLffayeFling1w3zSV9UxY7In4PqYWYiWrQiwX6P4Ze/vumk8lxbnpduNVaSkmZkXGkzZ7jFSlxa47lplqVHThjdpxRepFYACig7sVy8T9kazyVW4tI2zw03fxMAHfsg8mEHvCR74okn0rp168S29evX06hRH4+Fqq+vp+rqalq0aJGjJ5NJWrx4MZ1wwgn7fM9QKERFRUXiHwAAADCUDPgd5o033kgnnHACzZ07ly688EJaunQp3XfffXTfffcR0cel2NmzZ9PcuXOpsbGRGhsbae7cuRSNRunSSy8d6MMBAAAABoQBv2BOmzaNnnzySbr11lvpBz/4AdXX19OCBQvosssuc55z8803U19fH82aNYva2tpo+vTp9Pzzz1NMm+bxzzAaR5PhC9HXr/6L2P7lzac667qFHwrtvus4cvK1Dy8S2venPuWsH+isE9pXi7Y566tfO1FoESVaMXLDB0IzozwdufxI2Xmn1MfarvUVQisiLsn2NchS55okZ0cKtsmIy47Tg5QLq4+nkPRVyjpJRyvftRfG5ZQTFV+H/JWpGMOlVr3EnSrg5w4zZfcgtQ2LGdXyGgn+vJmQVnpUO/1osRJblGRl2bAvo3QMsmQRMW6zlhUrUaeVpF2iDy6dfiw9VqKsU5bbJJPcA6QzWt5ALddmXKIj8v300qq34dL9jod8krryaK/L2Cgsg3/OoLTGO/fcc+ncc8/NqRuGQXPmzKE5c+YMxu4BAACAAQfN1wEAAAAP4IIJAAAAeCCvp5V8ODtMZjRM1xRLz+03C7gcXNn1ttBKTP7Iu/44SmgX38ZeaOOi/ye080/9hbOuWCx9wt4qjizY2pQMo2Gks7505BtC61Ba7BWv03wuxc89bNQuob3RzRNRAjvahFZaxXGYbisuNFI8xkS51jKtLbTP5xFJfyfQIY+zJsKxklZL/jqlCvi5xUr0hojI8LNvGApLzU7x43RE7s+vxEooKCeZUCq3odWTVn5GaemZJpU2c2ZGbyXnsTXefsRKRNu8rPZ3vL+UFh0xXVrjBUzF91UMOr01nhpV0aeVuE0yyfRz6Ihl536h5TGQ4uZ9ur9wiF8HDnpwhwkAAAB4ABdMAAAAwAN5XZL920n/Q7GYSZ/54BKxvfJhHgy95+KjhHaDMt2j9smNQtt0C0cfap6R5b5fTj7WWVe8ulNoiZE8sNqnlGCJiNqOLHHWn4vJmZ+rEhzlKPsgITSq4ekhp1XKsvKzO3kCS2Sv7Cw0oZxLpFvTWslLKQVaFTKqEtgsO/ioJGyuRQY7pDYiwiXh1kxUaKkC3l9MG2Nh+PjnUBjRPrvS6Scdlq8LdXLtU+/0YyZzf//rTSs/z7Te6Yc1I6WXMJXOQvvR6cdUypt2VuREOZSsTj/eYiXZnX72rWV15fEYOXHrAuT+uv5NHel32VXDGuSB1QfF9JCD4TMcIHCHCQAAAHgAF0wAAADAA7hgAgAAAB7Iaw9zazpCBWmT0j+uFtsDEfYiR315g9De+tMkZz1811tCu2XL+c66+CX5ugfPPN5Zj924XGjBDvYN208bKzR1QslIf6HQfr77aGcd/ki2zesdz5NbZhTIdnv3bj+Zj6VbRmqOKWKTcV2qUmhmhCMnlYrXSUTUu5qfq3uD3TZ7iqF26RHVBNqddXO6WGiqhxk1pCdsBDmaUxqW7f3U2EdaDlyhyG5l/wH5nmYitzkTV1vjZaR/KzxMzfdNeY6V5N63ndUaT4mVaKMc5NSR3FpGj5woHqAaHfEZuiebe1qJZedujac+M2sCinKO3LxIN39TR31Pt5hHv1vqDTX5cpzAFdxhAgAAAB7ABRMAAADwQF6XZP/fU18nMxymMc/JDjrbbuK5mssafi60f/sjd9BJzpCRk/ee5/pf3V75npWvcKnVp83jzOxtddYtxwqJSsdx7EPt7ENE9PyW8c56+A45VaXjrBHO+vCgLCEGtymdhrROKkdFuET7avd4oRkxLgkfVrJHaOtbeVqKEZHDs/cq5cZQpyzj1QY4VvJhQpbGU0oFOmDIiITapac0LCeZtCsDnjNarMSXUPYf0GIlsmGQoE+JlYS1bj69FkdqsmMljJHRS5G5h0v7DOW7qJbQMJU6Yjojz4vaYUefZOLW6UeNlahlXr1jjzzG/pVP3d6zv+xPrMRrhyD3HAu6+ew3OGe4wwQAAAC8gAsmAAAA4AFcMAEAAAAP5LWH2Xj3ZvKbQeo+TxqHZ17O/uPyhPR6Mh82OeuPvl0htHH/y1ELY5L0/8pf3+Gs49MahRZayS32xk+RMY9Pl69z1ov7hgktvo5jGHZK+pRd9bwuNqWnWLiV12ZUtqNrDHCs5OftdUKj4gJnOaHwXSFtaWOP1iwsENquDJuRoXZpFFb6upz14oQ8Z+koex66h2mE2S8uC8r2fm0ZNgQzWqzEl2DNDmmxkqRiWml5g3iaf9XDGWk4xi0lVqJpKcW2cYuVuGmU0eMh6rQSfZKJ0hpPb3+ntsbTIydCc4mV2N6mlfQX19Z48MDAgeZf/BXHHSYAAADgAVwwAQAAAA/kdUnWTibJNolKvy3LoD+uXuWs65++WmjjpnK044enPC60B2eNdtZbb5kutBHz3nfW275SK7SRSX7dt0Y8IrTGAJcb1U5CREQlXK0lUxkYTUTkb+h21glblkFj27j+Z5aVCq3KxxGJDS2y5FxXzt+PJkS2C+3lvVwStotkR6ItKZ7G4u+Uk0XKfDykenu8RGjpApcSnBIrqQh2Cekjm2MzeqcfM8Gf3Q66xEoM+V0wkeLn2npJ1q3Tj9oZJ6N3v1E63LglHazcdSC3AdL6JBPXTj8icuJXtuvHrE4r8T6RRC3X6qVVEb3R3ifjMYLi1rHHtZvPYJR5+1u26/fA6n7uDww5uMMEAAAAPIALJgAAAOABXDABAAAAD+S1h9l0zVjyhcP0QeOvxPZHu9jXG3dfXGgffZG9wstiMs7wcDFPMqk/s0lo1j0cARlzkvRMt3aMdtanRLqFFjLYD1zxXr3QGtdxSzijrkZo00bwPjampIcZ2caeX6amTGghZSpIollGTuIV7LE0BGRrvEAbe7uZUvm6LclyZ212yvZ+JcpXruYe2TLQKtD6xSnYEfZaS/09msifIROWvpCRVDxMLVbiU5I5himNIdXDJEu+Z2+Gj4XSeqxE8fzSuh+YuzWeOGYtVmIq31N1D1N9lNZb4xkurfEU/yxue51WktundGt/tz9TR1Syvc/BjZkMSowlX/zGfDnOPAN3mAAAAIAHcMEEAAAAPJDXJdk7LnyQojEf3bFXdt7532dPc9YNy+TUka/9hst/T/fKzELXKdzt5r7RPxPatcd+01n/96j7hPaVaVflPMZui0vCJWtkCTGwcQvv+7hRQru49CVnvaSvQWjGLp6O0n2iLPOqEzQiO2XZrrecS1S1PllDNDr5vCRGytLqZqVDkdEtJ4sUKiXgvT2ylOsr5PJpypb7syJKrMQvYyVEJc4qqySrxEoyMfnzM9VmST752VMp5bEty5QJJYZhuJRkDdcB0rm1rE4/Sk7Cyur0w+usTj9KCdjKGjy9b02PjuhxFBVLLT9nDYn2VuMbqHKtV62/5Mvgadvts+fJZziYwB0mAAAA4AFcMAEAAAAP4IIJAAAAeCCvPcxp4Q4qCpv0Hz/9itje+GKLs06ddLTQvl32G37eC18Tmn02G1GHB6Uft30Ge24nhuX3jCsPf8tZv9wn28qplL8tIxnpFo52tI4bI7TjIhwr+a9t5wnNam131l0jpFfXZvE+os3S/+irZNOj2JT+n93FPmK8bITQtnRzTMfX0ym0kMG/Qr3dIaFFC7mNnu5hZsL8uhKfFitRsMLSgzNSiocZ0qIVSaVVneZhZtL82M6KlXArPrLk/pLKd0ojo/t6/NhtWolb2zzdw1R/s7J9St6fHitRvcqMOq3EJbqh+p46+9M2z3LR5OtySv0GNl5+49Ea/8SAO0wAAADAA7hgAgAAAB7I65Ls6cuvJF80RHX/u0Jsz6S5M87G/zxaaKuVTjEjH5Nlrc//+Hln/Xi3jFaMO4k7/2xJy24+l5fw/mdt/KLQSoJcIg2slxNC1AhIzzg5QLrezyXTlVvkIOj61Nv8uhGyBLY5zaXjgmZZJ2w7gj+vPtDZ6uP4S6JUfo9q7uLuSDWJ3ULzKVNBrC4Zmymu4GHWvdrElUxUKcmaMqoi/uZfK8mSKMlqXXJcYiVWSnmuFivpU0uyWbESfh8zJV/nvdOPfKx2+rEyenSEyeoCZLjFSmxFyz2RRE4ryd3px5dVds3dIcgNtyEuKu6xEs+7Gxi0/WVsr58CHOzgDhMAAADwAC6YAAAAgAdwwQQAAAA8kNce5vCfGeT3m2SMk63j+urZf3zyU78Q2mWrOIIyfNHbQvt6yYfO+sjXviq0h6b/2lnP3z1TaAtqljvrD1bIFneZEvbcxu5aLjTfMJ40ctSYrUITHmOTjLiQyZpRJ/2/tYlaZx3eJTWrgmMfui9jJ9kAjMsBKJTojDjr6qT0WlX8ndI3LI9wXKRLi3Kko/xdrcRMCI0UX9QX1vIayuQWK6T5eCJWon0XTKoepha3ySjea0b3MPk/EVOPlSi+oR45UdGnlahkeZGKYZfdGs9WNH1ayb4nmQQ0AzXj1v7O4/dnt0kmA9XizvLofrq+p5v3ORiTTMBBD+4wAQAAAA/gggkAAAB4IK9LsrTyfSIjQOsfPFpsLi7mOEOD9gljj3G51iySXXlaM1waLH2mQGjHnsxlu4veOkZoN5zzirOuXCr311PNkQUjEBSaNZKHRp9ftUhobRkupxZtlO/pK+bPML52l9CWd/P0El9Lh9DKh3FptdOSg7XVMmWyTCuHdQT2+TwiWdoNdMkaWFWEuwJ1WDJykorwd7WYqU1OUSIh4bCMo9hKSTatxUrUkiz55Q/eSOf+bqiWZG2t009cGWZt6AOk1U4/brES7XSaSq3QtnLXDfVYiVqS1aeHmKR2+mEt5DJA2rXTD+WOnGQdp8fqZlaHIOX8DUVyxBqIgdWYHnJIgztMAAAAwAO4YAIAAAAewAUTAAAA8EBee5jtl0wjXzBMr8/4cc7nfH7dxeJx8dNrnfWez08U2n/tPNNZly9qElrTf3M7vJrF8nvGb0+c7qxLVkhPMVrHkz7MUcPl8Y/jlnMzItKoXJNif7W4SYtyVHDu47jSd4X0fPPhzjrSvldoY0v5MzTrnpsSZ7DL5P4CW0KUi4TNsY+A7BhIFUHe0G5FhJaO8P6iWu8zNRISDWmfXW2NF5SvC3Uprep0DzOV22CKZ5TnpmWMJalENIyM7geqsZKcb++q2Rndi1QOJas1nhIrsXLHStTWeLpPabnEStw0eRzeJ5kMBPsTRwH/IvBhXcEdJgAAAOABXDABAAAAD+R1Sfb4a5ZTqDBAm9Oy3Ffr5wkhnb+Ww5BLMq3O2rxQTt5Y/OIkZ12/8w2h/bTlVGdd+nfZleeRtdOcdcPGNUILdXM8pGu67ALUNo6/r4z0y24+D7ZP4PfY3Cq0pFLmPaFgg9B+3XKCsz6sRx7nhEIukW5OlwrNDHHZtaREDnROreHJKXqpU51CEuySpbOqAMdKWjIxoakl2bA2OYUCHOWIhWQXIDutTiuRLzP35o6VmEm3kqza6UeWgGWsRJYiU7bXkmzufeuxEp9SE9OjI2IiCeXWvHbz8bmWVvVSrrdpJVn7U8/RYJRWP0lTTsBBD+4wAQAAAA/gggkAAAB4ABdMAAAAwAN57WHOrX6bimImHfbwdWJ7tLHdWdf+YaXQuj472Vk/eMR8oV0791pn7Rt3mNCeeWuYs27c9pbc3zL2Jg1TGifpXS3Oes+RY6Q2jv1NvW3Xi83jnHXBzhahdZ1Q7azHKT4hEZGxk/1GsqSxNiGy3Vm/F5cRF6OAPdSRxe1C29bOMRYjKNv7dShTSIJd0veqCvD77E4XCS2tWLYhQ7bNM4L8uDjYJ7ReZZpIRp9WklD2H9Bb41FOEkqsJKRNVYkrLf2yYyVM1iQTpWWgbhX6lGkspHmYpmK86a3x1HZ1KS1WorbGs1za36m+qFv7O99+TRb513HzRXXvM2MPRIs7N22IYyzwWvMG3GECAAAAHsAFEwAAAPBAXpdkr916HAULgzRuvuzK0zO5zln7qiqEtvtCLvGN8svyou+t95z19munCq1mMRfgfOXDhFa1lEurZmO90KwNfGzWpC6hnTRyk7Nen5Jxhq2by5312B75+bpHcA2n0ifjKNFm1vQISENgj7P+y96jhWYU8nSWMYXbhba7gz+TEZURnr0WZzv0kuwwH8dY1vbJeI+aBDK1mpQRUEuycgi2LMkKicwk79/WSrKmS6efRJqfG3QZIK0PiVY/bX87/ZBL5CSjR06UUmH24GllWomdOzpiucRKMnbu789qudY1VuIyEWQwugDpeB08DQaYQ6QbE+4wAQAAAA/gggkAAAB4ABdMAAAAwAN57WGuu2cC+QNhKkmuF9tDzy531k3fPV5ov5l2t7P+7q5jhabGGWKfaRZa8Vfjzrr7OBkPKXj1A2e993NHCK28j1u7fa5Rts07sZCP+2/d8nXRJiVqYcoIQe9IzkiIiAIRRZvZwzEVX5KIqNbHZtq69kqhxYrZz22MyIkrKzt4f2r8hIioOV3srANdKaENM9l/bE7IWEkmyp6H/hkoxMdSFpDtC3covp7uYYrWdbqHqVrEWs+0ZEY5v5qHqbbGo6zWeMr799fDdGmNZ2mxErX9XdrOraVsrdVgP9gfL1L1N7MiIC77ENNe+umBuba/G5RWfAP/liB/GPA7zHQ6Td/97nepvr6eIpEINTQ00A9+8AOyLOUPMmyb5syZQ7W1tRSJRGjmzJm0du1al3cFAAAADiwDfsG844476N5776W7776b3n//fbrzzjvpxz/+Md11113Oc+68806aP38+3X333bRs2TKqrq6m008/nbq6ulzeGQAAADhwDHhJ9o033qDPfe5zdM455xAR0ejRo+l3v/sdLV/+cZnUtm1asGAB3XbbbXTBBRcQEdHChQupqqqKHnnkEbr66qs97yv2x2XkNwK08fsniO0Nj3IZ72sXPSe0E8P8HeGrf5Hl2uqTuaQ4f9yvhPaf23kiyfbZcurImL9yt53dx8qyXaS1yllfUvIHodX6udQ5v+kMoRVv5PfxlRYLrWx4u7PusGQnnIKd/BmMMjmRpNjkLkDNrbJEGinlWlNDUHYWCnZwPdMu1EuyJXyc3XKySLHJx7I7Xii0dCR3ucxWSuOlARkrIYs/g5UVK+HzaQe0Tjhqpx+tBJxI8X8GttZFJiE6/cgCoyhFZkVOlHKjW9LBRdOnlahHrcdKTDFAWu3mo5eR/YqmH7M65UTvapS7Q5BX9qeaKcu1/drdJ4v+locH47MfDOfzADHgd5gnnXQSvfjii7R+/cf+3Ntvv02vv/46nX322URE1NTURM3NzXTGGXyBCIVCNGPGDFqyZMk+3zORSFBnZ6f4BwAAAAwlA36Hecstt1BHRweNHz+efD4fZTIZuv322+mSSy4hIqLm5o//mKaqqkq8rqqqijZv3rzP95w3bx59//vfH+hDBQAAADwz4HeYjz32GD300EP0yCOP0MqVK2nhwoX0k5/8hBYuXCieZ2h1Ftu2s7b9g1tvvZU6Ojqcf1u3bt3n8wAAAIDBYsDvMP/93/+dvvOd79DFF19MRERHHnkkbd68mebNm0dXXnklVVd/PGmjubmZampqnNe1tLRk3XX+g1AoRKFQKGu7dcIksvxhWnDZr8X26wq/7KyfKdsotLva2H9s+P1eoX1wTYmzPjYkJ2j4KrjF3rEnfCC0dqVV3tTJHwpt7Q6eOnJEUJ7ugMGfacsG+dkbm3qctT1cRkCOqeQvDJvT8ktGaBe3o0tXSp8yYLCvZ+0OCy1exh5Lnb9DaL5OjtSki2VrvJ3JEmdt9MSFFlMmt+zpkx6mHXEJHKjTSnx9msjHnQlJX8hI8Xva2s9PsVOzJ8pk1OkhuaeVUEb3AxXPL8vDVKaVuEVO9GklyndYPVYijlmbVqJOJcmI9nfa53Fpm+e1/Z0b/X1df2Ml/cVtf/32TOENHvQM+B1mb28vmaaWEfP5nFhJfX09VVdX06JFixw9mUzS4sWL6YQT5B/vAAAAAJ8UBvwO87zzzqPbb7+dRo4cSUcccQStWrWK5s+fT1/5yleI6ONS7OzZs2nu3LnU2NhIjY2NNHfuXIpGo3TppZcO9OEAAAAAA8KAXzDvuusu+s///E+aNWsWtbS0UG1tLV199dX0X//1X85zbr75Zurr66NZs2ZRW1sbTZ8+nZ5//nmKxWL7ta+OG3vJF83Q8eF2sf2O8x5x1gvaRsvje/4zzvqwtW8K7cqTOT7xYp8seXWfwBM7fjz850L75lE8wPo7tbI8/LVJckqHSq/F+yv6QO7Pv5WjMd1TRwrtxOINznplXGrG3nZ+/7GjhaYONQ63yCpAvJRLVBU+rdTZxdGO1EgZcdkW5+iK0SPLp1FlMHR7nywBm1HOeaRsWbO0wvxrWezrIQnvzwrmLslmYtr+1CZEPnmu02nlsS3LlAklhkFW7pKs24Bq11iJNq3Ep9QDraxpJcqhuNT/1FiJPkBaRE72Y1qJpZafswY6e6tFDka5dqhLuZ8kbLfPjvLwoDDgF8xYLEYLFiygBQsW5HyOYRg0Z84cmjNnzkDvHgAAABgU0HwdAAAA8AAumAAAAIAH8npayTNHPkZFMZOmvvn/xPY1xz/orCfed7nQxjzPnpjviHFC+9YwzoqeuPzLQuuewd8tjgjKaEXzsRwPOT4k/bizx3JT+VVJ3U9i76x0fVJomT2tzrq9oUFox4S3OOufN58m37OdIyE9VfL7UKfFsY/IHi1uUMamR8wMCs3uZQ8zUSz9v519HF2x4zJWosZYenukpxiO8OfN9jDZ+yzxaa3xxPM0DyfFRqIVlJ/dTKmt1qTBk1E8TNslVmKk5XEmle+bemu8jNJizz1WklvTPUz1E6VdJpm4+pRq5MSlxZ3ufYrjcDlo3ad0s2/l6zw+cT+AjZffeLTGhxTcYQIAAAAewAUTAAAA8EB+l2R7Kylq+mjkHfLe/Vv38mDoht9sEVp66zZn3TRHNkpQJyT4ny0R2olXcWl1bVLGJ8xj2521Xl68tOwNZ/1Iq5yOElWmGkfXy0HJ6RRrXQ2ysNWg/NRWtQwXWkV8nbPurZHnpVk5tOhu+Z5do/i7U8iQXXLsPi61Jorle7b0cAefYX1tQlNLspke+asWK+VRbglbZjIyYX6dW0nWDsrPYCgl2UxWSVZ5oMVKLLVbkh4rsZTjzugldW+dflyHS+9HSVY96oxWklXLpOoAab3sKuMh2uchl+iIW4zFY4eg/pZrAfikgDtMAAAAwAO4YAIAAAAewAUTAAAA8EBee5h3PvwF8oXCNGL5G2L7yw+yV1jTvFxo/tHcSu7cz8rXzd3Nr6v+23ah3Xrrc8563s7PCO2rY3nw9bO95UL7bAH7epevP0JohQXsDVbu2CQ0Q5nOUjy6Xb7O5IhG23bZqq5CWSeqU0LbnOa2cuHdMsaSKpO+pYoVTzjrZIn0spLdHLEpS+fuD2f2SN+wOMSfPa75hpkwf48rMORxqqMkDC3CQ0rswwposQt1WonmYdop5bm29Nn6Msp50VrjJRVXMStWonqHLmadkdGjI3wstsu0Er01noyVeJtIopNxaX8n9jUI7ej62/5uyCeLaK/L2HBiDyVwhwkAAAB4ABdMAAAAwAN5XZKtu28t+Y0g7b3iOLF9+EM84Ln988cIrXs4f0d4oupxoU147HpnfdgmOcnk8GDUWS9ZMkFoP7nwWWd9ybpLhPbZw5901oF3CoTWOYzLmRWJdULzj+C4yKeGfyQ0tQwU3SJ/hGopt6S6S2jvxfk9A3vlFJBgKZd5E7Ys5ZLFpc5ksSyPJbu4K5DtUpL198haVmmY4yJdWkuPtFKSjZnyWNRyaiAk92cn+bmZkFbqVDr96LESSuf+3pgUsRJZAlbjG3pJVuzbRXMr19raeVEnmbh2+lFjHlnTSvh1AbcWRBpqhyDTpUOQrqkffaAmi1geAyn93t8hPAEFuIM7TAAAAMADuGACAAAAHsAFEwAAAPBAXnuYZmkxmWaIPvXNt8T295/kdm2Rr+0Q2shIt7PenJaRhVHPsAemxk+IiN5Jsqc5/BXpoVRewt7k1uWyVd3aMeyzVbwj/bjuGj79ZjQqtNRIjqecVvyy0Foy7P8VbpN+i1nE00MOL98lj6W71lkbbZ1CqyrhY+uytCiHelzF8rObXbl/hdQ2gbqHWR5kD7XLkpGWdJifG9X9JENp4RfK7bVaAc3/Uz1Mv+b7pnNnDBIZfq6ttcZL2azpHqbVz2klpuI/6okF9dttdms83l/GZcyDGisJuURO3KaVuL2nG/vVNk89f56PpP9YLr6sZ9y8z0/g5A2w/+AOEwAAAPAALpgAAACAB/K6JLvu+hoyI2F6uuYvYvsxl37DWb88fr7Q1FLP2e9eIbSS13kiSfOVk4X2o+1nOeuCN5uE9n6SS6RVS2Up63dnTufXrZUl0kDnMGdtjKgRWmc9R06OCbUI7b0Ud/eJbU0IjcpLnOXk4pVC+vO2o/h1nfJYRhfxZ9iV0b5Hqd11imW5NtAkB0OrqCXZgEyx0LAgl8bbLTmQWy3JhrVWLkaAf2WjQa0kK6aVyNf5+/jnYvjk5zNSuetlcaUkq5Z8iYjitjJcOqOXN5WSolunH7dYiZX7uCyXsmvaUqaV6BNJ1C5ALpGT7BKpty5AbsOlB4OBiqoAD6CsjDtMAAAAwAu4YAIAAAAewAUTAAAA8EBee5iPnfUrKoyZ9NUtp4vtk69a46y3ad3aKnzseaR/Xyk0297G2lntQlu6ZLyzHrNbTjn5TeuJzrpo5U6h/XnDkc569Lb3hRZUPLeeo2UcpbOBv8vU+GTk5MH2w/g9dnQILVnL/uZR4S1C+5/WTznrgr7NQhtbwCbj9nSR0Iwgt78rKuoTWlqZVkKmbDnXq7TY8/dIr6ncr3iYGdkyMCM8TK2NndLWLhKQHqattK7LBIUkW+PtR6xEtMaz5C9TUm2Nl9YjJ/2LlajoHqZPMZH06Eiu1ni+rFZ1ub1Itf2d7n2q6D6l6qfuT3Qko56jwfAiB2PKCTikwR0mAAAA4AFcMAEAAAAP5HVJNmJkKGrY9P7PJorti+f/0lkf/sosoU2q47JrxVNyQkjyeB7wPP/IhUL77/u/4qz9w2uF9vi71c66cfMqoZnvjHDWtjbtIrOL4yKt40cLra8+d7edJa0N/KBlj9B6j+ER0o2BNqFZu5UIiBaROCzEMZONSVmqNiP8uqqYnIDS0slDqc2g7NjTZXFJLKiVZMuUkuzeTKHQMsphBrSSrKGUU2NBGalJiZKsNq0krZZkfZpGOVE7/QSyppUonX4svbypvL8+XFpp4aMPkPYpnYzIJVaiTzJRp4So5dqsaSX9zAZ47eajMxAhE7cyr07GHoiOPW7aEMdYUDr+RIE7TAAAAMADuGACAAAAHsAFEwAAAPBAXnuY5710LZmRMI197E2x/eXb2QSrv0++5qOjG511TedyoW0+O+SsT41Iv+qnb2101u2nHCa04reUeEFQ5hnK17BB5q+uElp6Z7Oz7honIxJjR7GmTichIvpgB7/PmM41Quup5u9AVT55LOHdyvcj7e/qRwfYC/1D9zShGQUc+xhV2Cq09q46fl44JLQuxeMLdEs3a5hPmRqTKBdaRnkbP2mxEsUnLQrEhbRHaU9n6bGSJGu25mEabh5mmj+DP8vDVN5Hn1aivn8/W+PpHqap/Mz0aSU+xVtza42XcWmNJ73P3HEU335ER4TmMhFkf3xKlf2Jo1gD4qiC/eYgal+IO0wAAADAA7hgAgAAAB7I65LsuJ+3kd8XotSn5GSRa/7GE0IaF8vh0iM+4o46PacfJbSzPs0l2qUJWSLN7NnrrHfOlCXZxoUctTDG1QsttoajI4nxMo4S7OOuOeMOk4OuT6lY76xXJmXJ0tiqdNfR4iG91Vz+iJqyLhnZzZoZkuXTWj8fy0fdFUKzC3h/o8IfCe19pdRqhOXkktYMdyjy98rjLDG5zLw3JTv9pCN8nCJmQTJWUhSQQ7B3KyXTrJJsSinHBfyappQ+tVJ1Si19apGFuKVOK9EiQ8pTXTv9uGh6BVF0+nGbZOKSRRBdgPSOPV47/ejl2kHOPmAiCfikgDtMAAAAwAO4YAIAAAAewAUTAAAA8EBee5j2th1kG0Fqny9jAuNu47iBPVW2zUuvWOust9wuYx5/rHrFWZ+/9ktCKx7BbdjOnb5SaBtuZsNsz0WThDbs/1Y4693nSQ+zdm8N76/6NaEdrUwaebRtutAKtrFnZGheZKaGj1NtwUZEFNmj+I2xmNDKTP5V2NJRIrTKIvbqRoVkK75Al2LCRSNCa8nwPvy90hOOmdz6rzWlTyuh3Cj+Y8wvYyWkxCIysksfGSk+TtvnvTVeMq0819Inkiit8VxjJbqmPHaz5+zc3mBWrESdVmJ7nFZCuT+P7lNaHr9bZ09AUX5Xs7TcZFxPDOM2dcR1IsmgTEcZ+LcEnyxwhwkAAAB4ABdMAAAAwAN5XZLd+dWjyRcK09LJPxfbP/s2d6pZ/z+ya81hYY6S3HXiI0KLGlzH63quWmjWSVy+urHiMaFd03OSs95zrCw0lf2GS4+dk+QEksIdPOz59AI5OaVcKRu+tqNBaLFtvA9faYnQaqranXWbJYc9R1qU/ZfKIdERg8vK7W2yRFpaxLWm4X45ASXQxe9pFcpa6m5lELXZLT97zOTPsDch92eFc0cabKXTT7GvTxO5JKzHSgwlVmIHXEqyWowlleHn2nqsxFaHS8tjTqqlz34OkNZjJaby/VYvKKpHnVbKtW7DnnUynsuuWocgyt0hyCv7U830Wq79RDEY5eHBKAGjrOwK7jABAAAAD+CCCQAAAHgAF0wAAADAA3ntYX71qqcpUuinJ7srxfb0qVOc9cLT7xfaVcmrnfU5URlLuGPvEc56+LMtQnt/dpmzrg8UCk2dQjLz6PeFtquKj+3Ewz8U2sqNE5z1aH9UaGpLuLZNpUKr2NrjrK2qMqEdNazJWW9Lyx9vYC+/Lj1MfgZ1f0arNACTJeyxVClTRoiIzG4+h+lS+RlaUuxhGvGE0KLK3/y39snX2V49TH+vpqoepvSF1FiJFZWZE3VaiWFKEyeTUb5TavGQlKWc34zeZk6JU2TFSpR4j6u/6dLizsr9Xddym0gi2t9p3pnyMGvKiepT9tNzG4qJJAOB2/5coyrgoAd3mAAAAIAHcMEEAAAAPJDXJdkrirZRUcyko+++XmxPf53LhtNDssPMd077i7N+uGuY0O79+ynOeuy6pUK74Fj+bvFmXNbReiaPdNbfqPqV0G4b+3VnfXmljLG8MV5ONlFJ2HzcsY0yBuFr5mhHzyTZPejoQu4QtDYpNaONp3skxpQITe0KFGqV36PixVyiGubTSp29XJJNjSwWWnNCKcn2yZJs2ODP1BWX3YrMMNdI9W5FdohfFzO1WIlCVklWmSZiB2T8xVR/RbRYSVrt9KMdS8IlVpJSyqJuA6r3J1YiJK1c61Meuk4rEV2AckdO9OiIG2oJOKvTj0uMRWUwyrWH8pQT2+2zo6zcb3CHCQAAAHgAF0wAAADAA7hgAgAAAB7Iaw/z/A/OI39BiEbevUZs//m7zznrKzedJ7RH619y1vVPfV1oI5/mtb9Gtsa7oeKPznrWxi8Kbdc0jilMCUq/cc9RHHU4KdwhtOkNm5z1R2npx6keWHGTNMGsPXuddVfdSKFNCm111n9ok20Brc4uZ91bIY+zz+bWdSHZ/Y6SxWx6FBoykmGrHmZMvufuOEdX7LiM8ISU9+nrkzGWoOJhprWZFlaQf2WLfNq0EvE8zcNJK7GSgPyeaKb5uYZPamqsxM6KlfDnNTK5Yxh6rCSjtNhzswr1WIlPyTTYmjeYqzWePq3EzacUkROXKSe69+kV3af0+i7mIHhusPFAf8AdJgAAAOABXDABAAAAD+R1Sdb4RTkZ/jCZw2Spp0z5GvDhA+OE9sqtrzjrMY/JUmdwBXfi2XP+EUIb6efy4obXRwutcBoPVe62ZXyifRJnFgpNGWc4v4IHUS/qGS+0gNICpqCpS2iWUt7srhMSNQRYW902Qmj+vu3Ouq9SFqVaLT4X4VZZLGtv5BMaMuSvjFpqTRbK7197+vicFcRl5yRTKYql+mSZt7CcP2/K1kqySqwkashzLY4roHf64c9n+bVypvprYMrPYKWVx3qsxHKLlSjlWreyq9sU5f2IlQjNY9k1+3UuGuWOjqjsTxxFvq5/5VpwaOIxrTTg4A4TAAAA8AAumAAAAIAHcMEEAAAAPJDXHmbgxVXkNwL0/t3Txfbz137JWVf87h2hfe3TVzjrMYvfFpql/P1629k9Qvt7nF2V4a8khXbZ51911n/WTMVpEzY6649SctLHp8L8+KoNnxJacYhjJsZ26f+pIxNSI+SxlCo+6eYWOclkjMVt8+Ll0iVqznB7ulCbNNaSSsc7n9Y6zlamkCRj0liI9/GxRNPSLxbTUfpkHKUwxJ8prnmYmRC/rsjUYiXqKImg5oK5xUrU1ng+eSx2Ovd3yoSleK9usZK0PslEmVbiGiuRj01SIy5a5ERZ26L9Xe5YSVZ0hPrXGk99nT4BxRqAKSdufKImi2j709s6gvxnv+8wX331VTrvvPOotraWDMOgP/3pT0K3bZvmzJlDtbW1FIlEaObMmbR27VrxnEQiQddffz2Vl5dTQUEBffazn6Vt27b9Sx8EAAAAGEz2+4LZ09NDRx11FN1999371O+8806aP38+3X333bRs2TKqrq6m008/nbq6+C8fZ8+eTU8++SQ9+uij9Prrr1N3dzede+65lMm4/ckgAAAAcODY75LsWWedRWedddY+Ndu2acGCBXTbbbfRBRdcQERECxcupKqqKnrkkUfo6quvpo6ODvr1r39N//d//0ennXYaERE99NBDVFdXRy+88AKdeeaZno+l79wp5A+E6S/nLhDbr/72bGdtRGUko/Yx7irjrywXWno0D4Ked8yfhPbfSseg8HI5CPqCQi67nv3ul4R262HPOusnuo4S2r+XfeSs12+Qk0X8RVyWbGiVnYzMQo5rjBq+R2gBZQoI7ZQxFrVGZVXIUu6mFJ+LUJuMa1jFshOPip3memYqJrVED+/fTuUe2WH2yu9tRSEutfbaWokvyM+NmnISjTppxBfSvnwpX8asoB4ryd3phzLKc7VjEbES7cteSplkolc3M6R2+nEpKWZy1xT1Tj8qabd4iNqxx6Xs6tbpZ+hLq973Zw1EIAVtgEAOBvSPfpqamqi5uZnOOOMMZ1soFKIZM2bQkiVLiIhoxYoVlEqlxHNqa2tp4sSJznN0EokEdXZ2in8AAADAUDKgF8zm5mYiIqqqqhLbq6qqHK25uZmCwSCVlpbmfI7OvHnzqLi42PlXV1e3z+cBAAAAg8WgxEoM7c/TbNvO2qbj9pxbb72VOjo6nH9bt27d5/MAAACAwWJAYyXV1R9P+Ghubqaamhpne0tLi3PXWV1dTclkktra2sRdZktLC51wwgn7fN9QKEShUChr+7DrNlOgIEhRrb9Y4Z9WOOuts48V2oi7uR3dzi9PFlovHzJ9vlCWfW97naeCjGp/Q2ilvqizbltWKbQZR/Jkkf9ed67Qvln6gbMuWid/FPFyxYu05Oczyzkucnx5k9ASNvt6kWYtPqGcw/Jy6e02Jfi4fa0yUhMpZl9IfX8iEr5eqkjzvXrU1nG5/6DLLwe1UEmQN/RY8jNkQvylKqz93A0lFuQPSM/UFrESl9Z4WqyEXHzEhDKtRPc3k6I1nh7tUDxMl79zc7PudA9TnWTiFh0RMQ/N75P+phbnUaMjlLvdnkkubfOyfNGcT3XFsv91D3V/fFH5woH3b0H+MKB3mPX19VRdXU2LFi1ytiWTSVq8eLFzMZwyZQoFAgHxnJ07d9K7776b84IJAAAAHGj2+w6zu7ubPvyQ/0q0qamJVq9eTWVlZTRy5EiaPXs2zZ07lxobG6mxsZHmzp1L0WiULr30UiIiKi4upq9+9av0rW99i4YNG0ZlZWX07W9/m4488kjnr2YBAACATxr7fcFcvnw5nXLKKc7jm266iYiIrrzySvrtb39LN998M/X19dGsWbOora2Npk+fTs8//zzFYpw5+NnPfkZ+v58uvPBC6uvro1NPPZV++9vfkk8vh/0THm54mYpiJtU/faPYPqGOO+Ocd9nrQlv9v1wGrviC9EIrItx55/1kr9DU7j7+htHyPRNvOeuqpbKUVfw1HiDdsWaY0N49gss7petkqbO7k380ZkGB0FK1/BmOK1wktN0ZjoQU7JSlM0P5GRxWIuMo63v4D7WMLlmSrSziz9RlyTiKSjom92f25P55qlNIfH2yvFgS4JJsry1/RdNKSTaql8eUWEkwqMVY0m7TSpT3MeUxG2mX+IZSkrUzejcfpZNROnfUwbWhTlanH2WAdJbGZKzcERB16LWOWnYN9XPqiNt7uuE+AcUlcrLfR7T/WC5lZs+4lXIRY8kb9vuCOXPmTLJdPATDMGjOnDk0Z86cnM8Jh8N011130V133bW/uwcAAAAOCGi+DgAAAHgAF0wAAADAA3k9reTOvY0UTgTo8Dv3iu0ffpXbzD1d9WehHXfuNc76j40/EZrq2sza+EWhhZZvcNZ7zj9CaPftmeGsC1fJJvJb0uyLlr8tS9nPnjPJWUc3yM/gi7NPaVZVCK1jBLecOzIoJ5lsTHPbvIKdWgSktMhZToy9K6RFu8Y763B3q9BqC9gXbdWtLTU7Wyj359+aHQX6B6qH6Zd2MZUEeEOXJdv7yViJNH/UtnZhLVaitq7LaLESvzKJRm+N5+ZhJq3c0R+3WIlsjZfz7V01fVqJiuXSNk9ETgyXWIlL5ET3FN00lf2ZgDIQ9Ds6AvafQ8SHxR0mAAAA4AFcMAEAAAAP5HVJ9q/3n0y+YJgqt64S27/1+Ted9cNdMsqRvLDNWZeY8uOHDB4I3PS3eqGN6OTG8C0zZOnx2bcnOuux25cL7c9dXL4tWdMmtL9u49eVbt8hj0X5S+TEKDkIuquOv+fU+mXZ85ke7rMb3CXjIelhXK6dENkutP9r545Io/qkNjrKUZLmjIy4GH4+Z9GYnHJiK9NK9LhGwuaSqb9Pls7K/HzcnVklWV4HtGHWFFCOJSB/RrY6rSQgJDJTyv59eqyEcpJUp5VY8rPLaSV6tx3l/ftZkiW9048aORHbc3f6cZtI4obblJOBKrtmBqCbT38Z8sHTIG/AHSYAAADgAVwwAQAAAA/gggkAAAB4wLDd2vZ8Quns7KTi4mIaOe+HZIbD//wFAAAAQA6seJy23Ppd6ujooKKiopzPwx0mAAAA4IG8/CvZf9wUW/H4AT4SAAAA+c4/riX/rOCalyXZbdu2UV1d3T9/IgAAAOCRrVu30ogRI3LqeXnBtCyLduzYQbZt08iRI2nr1q2udedDjc7OTqqrq8N50cB5yQbnZN/gvOybg/W82LZNXV1dVFtbS6aZ26nMy5KsaZo0YsQI6uzsJCKioqKig+qHN1DgvOwbnJdscE72Dc7LvjkYz0txcfE/fQ7+6AcAAADwAC6YAAAAgAfy+oIZCoXoe9/7HoVCucdIHYrgvOwbnJdscE72Dc7LvjnUz0te/tEPAAAAMNTk9R0mAAAAMFTgggkAAAB4ABdMAAAAwAO4YAIAAAAeyOsL5q9+9Suqr6+ncDhMU6ZModdee+1AH9KQMW/ePJo2bRrFYjGqrKyk888/n9atWyeeY9s2zZkzh2praykSidDMmTNp7dq1B+iIh5558+aRYRg0e/ZsZ9uhek62b99Ol19+OQ0bNoyi0SgdffTRtGLFCkc/FM9LOp2m7373u1RfX0+RSIQaGhroBz/4AVmW5TznUDgvr776Kp133nlUW1tLhmHQn/70J6F7OQeJRIKuv/56Ki8vp4KCAvrsZz9L27ZtG8JPMUTYecqjjz5qBwIB+/7777ffe+89+4YbbrALCgrszZs3H+hDGxLOPPNM+4EHHrDfffdde/Xq1fY555xjjxw50u7u7nae86Mf/ciOxWL2448/bq9Zs8a+6KKL7JqaGruzs/MAHvnQsHTpUnv06NH2pEmT7BtuuMHZfiiek9bWVnvUqFH2VVddZb/11lt2U1OT/cILL9gffvih85xD8bz88Ic/tIcNG2b/9a9/tZuamuw//OEPdmFhob1gwQLnOYfCeXnmmWfs2267zX788cdtIrKffPJJoXs5B9dcc409fPhwe9GiRfbKlSvtU045xT7qqKPsdDo9xJ9mcMnbC+axxx5rX3PNNWLb+PHj7e985zsH6IgOLC0tLTYR2YsXL7Zt27Yty7Krq6vtH/3oR85z4vG4XVxcbN97770H6jCHhK6uLruxsdFetGiRPWPGDOeCeaiek1tuucU+6aSTcuqH6nk555xz7K985Sti2wUXXGBffvnltm0fmudFv2B6OQft7e12IBCwH330Uec527dvt03TtJ977rkhO/ahIC9LsslkklasWEFnnHGG2H7GGWfQkiVLDtBRHVg6OjqIiKisrIyIiJqamqi5uVmco1AoRDNmzDjoz9G1115L55xzDp122mli+6F6Tp566imaOnUqffGLX6TKykqaPHky3X///Y5+qJ6Xk046iV588UVav349ERG9/fbb9Prrr9PZZ59NRIfueVHxcg5WrFhBqVRKPKe2tpYmTpx40J2nvGy+vmfPHspkMlRVVSW2V1VVUXNz8wE6qgOHbdt000030UknnUQTJ04kInLOw77O0ebNm4f8GIeKRx99lFauXEnLli3L0g7Vc7Jx40a655576KabbqL/+I//oKVLl9I3v/lNCoVCdMUVVxyy5+WWW26hjo4OGj9+PPl8PspkMnT77bfTJZdcQkSH7u+Lipdz0NzcTMFgkEpLS7Oec7D9/zgvL5j/wDAM8di27axthwLXXXcdvfPOO/T6669naYfSOdq6dSvdcMMN9Pzzz1M4HM75vEPpnBB9PA5v6tSpNHfuXCIimjx5Mq1du5buueceuuKKK5znHWrn5bHHHqOHHnqIHnnkETriiCNo9erVNHv2bKqtraUrr7zSed6hdl72RX/OwcF4nvKyJFteXk4+ny/r20tLS0vWN6GDneuvv56eeuopevnll8Xg0+rqaiKiQ+ocrVixglpaWmjKlCnk9/vJ7/fT4sWL6Re/+AX5/X7ncx9K54SIqKamhiZMmCC2HX744bRlyxYiOjR/V4iI/v3f/52+853v0MUXX0xHHnkkfelLX6Ibb7yR5s2bR0SH7nlR8XIOqqurKZlMUltbW87nHCzk5QUzGAzSlClTaNGiRWL7okWL6IQTTjhARzW02LZN1113HT3xxBP00ksvUX19vdDr6+upurpanKNkMkmLFy8+aM/RqaeeSmvWrKHVq1c7/6ZOnUqXXXYZrV69mhoaGg65c0JEdOKJJ2ZFjtavX0+jRo0iokPzd4WIqLe3N2tYsM/nc2Ilh+p5UfFyDqZMmUKBQEA8Z+fOnfTuu+8efOfpgP250b/IP2Ilv/71r+333nvPnj17tl1QUGBv2rTpQB/akPCNb3zDLi4utl955RV7586dzr/e3l7nOT/60Y/s4uJi+4knnrDXrFljX3LJJQfdn8T/M9S/krXtQ/OcLF261Pb7/fbtt99ub9iwwX744YftaDRqP/TQQ85zDsXzcuWVV9rDhw93YiVPPPGEXV5ebt98883Ocw6F89LV1WWvWrXKXrVqlU1E9vz58+1Vq1Y5ET0v5+Caa66xR4wYYb/wwgv2ypUr7U9/+tOIlXzS+OUvf2mPGjXKDgaD9jHHHONEKg4FiGif/x544AHnOZZl2d/73vfs6upqOxQK2SeffLK9Zs2aA3fQBwD9gnmonpO//OUv9sSJE+1QKGSPHz/evu+++4R+KJ6Xzs5O+4YbbrBHjhxph8Nhu6Ghwb7tttvsRCLhPOdQOC8vv/zyPv9fcuWVV9q27e0c9PX12dddd51dVlZmRyIR+9xzz7W3bNlyAD7N4ILxXgAAAIAH8tLDBAAAAIYaXDABAAAAD+CCCQAAAHgAF0wAAADAA7hgAgAAAB7ABRMAAADwAC6YAAAAgAdwwQQAAAA8gAsmAAAA4AFcMAEAAAAP4IIJAAAAeAAXTAAAAMAD/x8OUc1o6BzeEQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pe.unsqueeze(0).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd87a29",
   "metadata": {},
   "source": [
    "## 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8e256b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, emb_dim=EMBEDDING_SIZE, context_size=CONTEXT_SIZE, vocab_size=-1, p=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p = p\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        # Like tutorial 6\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.embeddings.load_state_dict(embedding_dict)\n",
    "\n",
    "        self.identity_matrix = torch.eye(len(train_vocab))\n",
    "        # Freeze the layer\n",
    "        for p in self.embeddings.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.pe = create_pe(emb_dim, context_size)\n",
    "\n",
    "        # Weights in dim PXD\n",
    "        self.Wq = nn.Parameter(torch.rand(1, emb_dim, self.p), requires_grad=True)\n",
    "\n",
    "        self.Kq = nn.Parameter(torch.rand(1, emb_dim, self.p), requires_grad=True)\n",
    "\n",
    "        self.Vq = nn.Parameter(torch.rand(1, emb_dim, self.p), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(self.embeddings(x).squeeze(0))\n",
    "\n",
    "        # Usikker på om vi skal indexere ut embeddings eller kjøre input gjennom embedding.\n",
    "        # torch.matmul(self.identity_matrix[x], self.embeddings.weight)\n",
    "        embeddings = self.embeddings(x) + pe\n",
    "\n",
    "        # Get PxD * DxN -> PxN\n",
    "        q = torch.matmul(embeddings, self.Wq)\n",
    "\n",
    "        # Get PxD * DxN -> PxN\n",
    "        k_value = torch.matmul(embeddings, self.Kq)\n",
    "\n",
    "        # Get PxD * DxN -> PxN\n",
    "        v = torch.matmul(embeddings, self.Vq)\n",
    "\n",
    "        # (K.T * Q)/(emb_dim**0.5) | NxP * PxN -> NxN\n",
    "        scores = torch.bmm(q, k_value.transpose(1, 2)) / self.emb_dim**0.5\n",
    "\n",
    "        # Softmax .sum(dim=2) -> [1,1,1,1]\n",
    "        attention = nn.Softmax(dim=2)(scores)\n",
    "\n",
    "        # PxN * NxN -> PxN\n",
    "        # In the book they used DxD for v.weights, instead of PxD\n",
    "        weighted = torch.bmm(attention, v)\n",
    "\n",
    "        # If V, DxD\n",
    "        # return torch.add(embeddings, weighted)\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "660444ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "model_test = SelfAttention(vocab_size=len(train_vocab), p=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8453d12",
   "metadata": {},
   "source": [
    "## 4.3\n",
    "\n",
    "Note: we've got two slightly different versions of MultiheadAttention, see the report for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14caac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_heads=1, emb_dim=EMBEDDING_SIZE, context_size=CONTEXT_SIZE, p=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p = p\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = emb_dim // num_heads\n",
    "        self.p_head_dim = p // num_heads\n",
    "\n",
    "        # Got this from documentation, and I found it usefull\n",
    "        assert (\n",
    "            self.head_dim * num_heads == self.emb_dim\n",
    "        ), \"Dimension of embeddings need to be divisible by the number of heads\"\n",
    "        assert (\n",
    "            self.p_head_dim * num_heads == self.p\n",
    "        ), \"Dimension of p need to be divisible by the number of heads\"\n",
    "\n",
    "        # Like tutorial 6\n",
    "        # self.embeddings = nn.Embedding(vocab_size, emb_dim)\n",
    "        # self.embeddings.load_state_dict(embedding_dict)\n",
    "\n",
    "        # self.identity_matrix = torch.eye(len(train_vocab))\n",
    "        # Freeze the layer\n",
    "        # for p in self.embeddings.parameters():\n",
    "        #    p.requires_grad = False\n",
    "\n",
    "        #Here the first argument should be context size. But if we want to generate longer sequences with a transformer, then the we need larger position matrix\n",
    "        position_matrix = torch.zeros(100, emb_dim)\n",
    "        for i in range(0, context_size - 1):\n",
    "            for j in range(0, int(emb_dim / 2)):\n",
    "                position_matrix[i, 2 * j] = torch.sin(\n",
    "                    torch.tensor(i / 10000 ** (2 * j / emb_dim))\n",
    "                )\n",
    "                position_matrix[i, 2 * j + 1] = torch.cos(\n",
    "                    torch.tensor(i / 10000 ** (2 * j / emb_dim))\n",
    "                )\n",
    "\n",
    "        self.pe = position_matrix.to(device)\n",
    "\n",
    "        # Weights in dim PXD\n",
    "\n",
    "        # Using the register parameter to make the different parameters.\n",
    "        for h in range(num_heads):\n",
    "            self.register_parameter(\n",
    "                f\"Wq{h}\",\n",
    "                nn.init.xavier_uniform_(\n",
    "                    nn.Parameter(\n",
    "                        torch.empty(self.p, self.head_dim), requires_grad=True\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "            self.register_parameter(\n",
    "                f\"Wk{h}\",\n",
    "                nn.init.xavier_uniform_(\n",
    "                    nn.Parameter(\n",
    "                        torch.empty(self.p, self.head_dim), requires_grad=True\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "            self.register_parameter(\n",
    "                f\"Wv{h}\",\n",
    "                nn.init.xavier_uniform_(\n",
    "                    nn.Parameter(\n",
    "                        torch.empty(self.p, self.head_dim), requires_grad=True\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.register_parameter(\n",
    "            f\"Wo\",\n",
    "            nn.init.xavier_uniform_(\n",
    "                nn.Parameter(\n",
    "                    torch.empty(self.emb_dim, self.p * self.num_heads), requires_grad=True\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(self.embeddings(x).squeeze(0))\n",
    "\n",
    "        # Usikker på om vi skal indexere ut embeddings eller kjøre input gjennom embedding.\n",
    "        # torch.matmul(self.identity_matrix[x], self.embeddings.weight)\n",
    "\n",
    "        x = x + self.pe[:x.shape[1]]\n",
    "\n",
    "        x = x.transpose(1,2)\n",
    "        xs = torch.split(x, self.head_dim, dim=1)\n",
    "\n",
    "        weighted = None\n",
    "        for i, h in enumerate(xs):\n",
    "\n",
    "            wq = getattr(self, f'Wq{i}')\n",
    "            wk = getattr(self, f'Wk{i}')\n",
    "            wv = getattr(self, f'Wv{i}')\n",
    "            \n",
    "\n",
    "            # Get PxD * DxN -> PxN\n",
    "            q = torch.matmul(wq, h)\n",
    "\n",
    "            \n",
    "\n",
    "            # Get PxD * DxN -> PxN\n",
    "            k_value = torch.matmul(wk, h)\n",
    "\n",
    "            # Get PxD * DxN -> PxN\n",
    "            v = torch.matmul(wv, h)\n",
    "\n",
    "            \n",
    "\n",
    "            # (K.T * Q)/(emb_dim**0.5) | NxP * PxN -> NxN\n",
    "            scores = torch.bmm(q, k_value.transpose(1, 2)) / self.emb_dim**0.5\n",
    "\n",
    "            # Softmax .sum(dim=2) -> [1,1,1,1]\n",
    "            attention = nn.Softmax(dim=2)(scores)\n",
    "\n",
    "            # PxN * NxN -> PxN\n",
    "            # In the book they used DxD for v.weights, instead of PxD\n",
    "            weighted_temp = torch.bmm(attention, v)\n",
    "\n",
    "            if weighted is None:\n",
    "                weighted = weighted_temp\n",
    "            else:\n",
    "\n",
    "                weighted = torch.cat((weighted, weighted_temp), dim=1)\n",
    "\n",
    "        # If V, DxD\n",
    "        # return torch.add(embeddings, weighted)\n",
    "        \n",
    "        return torch.matmul(self.Wo, weighted).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f1c844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_heads=1, emb_dim=EMBEDDING_SIZE, context_size=CONTEXT_SIZE, p=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p = p\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = emb_dim // num_heads\n",
    "        self.p_head_dim = p // num_heads\n",
    "\n",
    "        # Got this from documentation, and I found it usefull\n",
    "        assert (\n",
    "            self.head_dim * num_heads == self.emb_dim\n",
    "        ), \"Dimension of embeddings need to be divisible by the number of heads\"\n",
    "        assert (\n",
    "            self.p_head_dim * num_heads == self.p\n",
    "        ), \"Dimension of p need to be divisible by the number of heads\"\n",
    "\n",
    "        # Like tutorial 6\n",
    "        # self.embeddings = nn.Embedding(vocab_size, emb_dim)\n",
    "        # self.embeddings.load_state_dict(embedding_dict)\n",
    "\n",
    "        # self.identity_matrix = torch.eye(len(train_vocab))\n",
    "        # Freeze the layer\n",
    "        # for p in self.embeddings.parameters():\n",
    "        #    p.requires_grad = False\n",
    "\n",
    "        #Here the first argument should be context size. But if we want to generate longer sequences with a transformer, then the we need larger position matrix\n",
    "\n",
    "        self.pe = create_pe(context_size,emb_dim).to(device)\n",
    "\n",
    "        # Weights in dim PXD\n",
    "\n",
    "        # Using the register parameter to make the different parameters.\n",
    "        for h in range(num_heads):\n",
    "\n",
    "            setattr(self, f'Wq{h}', nn.Linear(emb_dim, p, bias=False))\n",
    "\n",
    "            setattr(self, f'Wk{h}', nn.Linear(emb_dim, p, bias=False))\n",
    "            \n",
    "            setattr(self, f'Wv{h}', nn.Linear(emb_dim, p, bias=False))\n",
    "\n",
    "        \n",
    "        setattr(self, f'Wo', nn.Linear(p, emb_dim, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(self.embeddings(x).squeeze(0))\n",
    "\n",
    "        # Usikker på om vi skal indexere ut embeddings eller kjøre input gjennom embedding.\n",
    "        # torch.matmul(self.identity_matrix[x], self.embeddings.weight)\n",
    "\n",
    "        x = x + self.pe[:x.shape[1]]\n",
    "\n",
    "        \n",
    "\n",
    "        xs = torch.split(x, self.head_dim, dim=1)\n",
    "\n",
    "        weighted = None\n",
    "        for i, h in enumerate(xs):\n",
    "\n",
    "            wq = getattr(self, f'Wq{i}')\n",
    "            wk = getattr(self, f'Wk{i}')\n",
    "            wv = getattr(self, f'Wv{i}')\n",
    "            \n",
    "\n",
    "            # Get PxD * DxN -> PxN\n",
    "            q = wq(h)\n",
    "\n",
    "            # Get PxD * DxN -> PxN\n",
    "            k_value = wk(h)\n",
    "\n",
    "            # Get PxD * DxN -> PxN\n",
    "            v = wv(h)\n",
    "\n",
    "            \n",
    "\n",
    "            # (K.T * Q)/(emb_dim**0.5) | NxP * PxN -> NxN\n",
    "            scores = torch.bmm(q, k_value.transpose(1, 2)) / self.emb_dim**0.5\n",
    "\n",
    "            # Softmax .sum(dim=2) -> [1,1,1,1]\n",
    "            attention = nn.Softmax(dim=2)(scores)\n",
    "\n",
    "            # PxN * NxN -> PxN\n",
    "            # In the book they used DxD for v.weights, instead of PxD\n",
    "            weighted_temp = torch.bmm(attention, v)\n",
    "\n",
    "            if weighted is None:\n",
    "                weighted = weighted_temp\n",
    "            else:\n",
    "\n",
    "                weighted = torch.cat((weighted, weighted_temp), dim=1)\n",
    "\n",
    "        # If V, DxD\n",
    "        # return torch.add(embeddings, weighted)\n",
    "        \n",
    "        return self.Wo(weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5c8a1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train = nn.Embedding(len(train_vocab), EMBEDDING_SIZE)\n",
    "embeddings_train.load_state_dict(embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05abef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "conjugate_words = \"be, am, are, is, was, were, been, being, have, has, had, having\".replace(' ', '').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9232d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_t, train_context, train_targets = create_dataset(\n",
    "    train_token, train_vocab, CONTEXT_SIZE, banned_words=[], only_words=conjugate_words, position=\"middle\"\n",
    ")\n",
    "\n",
    "val_dataset_t, val_context, val_targets = create_dataset(\n",
    "    val_token, train_vocab, CONTEXT_SIZE, banned_words=[], only_words=conjugate_words, position=\"middle\"\n",
    ")\n",
    "\n",
    "test_dataset_t, test_context, test_targets = create_dataset(\n",
    "    test_token, train_vocab, CONTEXT_SIZE, banned_words=[], only_words=conjugate_words, position=\"middle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87352de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), 124031)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(train_targets), len(train_dataset_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b035bbdf",
   "metadata": {},
   "source": [
    "## 2.2 (returning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e511138",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConjugationMLP(nn.Module):\n",
    "    def __init__(self, embedding=None, context_size=CONTEXT_SIZE, use_attention=True):\n",
    "        super().__init__()\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        (vocab_size, embedding_dim) = embedding.weight.shape\n",
    "        # Instantiate an embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Load the pretrained weights\n",
    "        self.embedding.load_state_dict(embedding.state_dict())\n",
    "        # Freeze the layer\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        if self.use_attention:\n",
    "            self.multihead = MultiheadAttention(p=embedding_dim, num_heads=4).to(device)\n",
    "\n",
    "        # Regular MLP\n",
    "        self.fc1 = nn.Linear(embedding_dim * context_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        # out is now of shape (N, context_size, embedding_dim)\n",
    "\n",
    "        if self.use_attention:\n",
    "            out = self.multihead(out) + out\n",
    "\n",
    "        out = F.relu(self.fc1(torch.flatten(out, 1)))\n",
    "        # out is now of shape (N, context_size*embedding_dim)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5220b1",
   "metadata": {},
   "source": [
    "MLP with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "156135a7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "tst_MLP_attn = ConjugationMLP(embedding=embeddings_train, use_attention=True).to(device)\n",
    "optimizer = optim.Adam(tst_MLP_attn.parameters())\n",
    "loss_fnc = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8994a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "behave_train_dataloader = DataLoader(train_dataset_t, batch_size=1024, shuffle=True)\n",
    "behave_val_dataloader = DataLoader(val_dataset_t, batch_size=1024, shuffle=True)\n",
    "behave_test_dataloader = DataLoader(test_dataset_t, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b60a64ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1, 11, 11], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_MLP_attn(train_dataset_t[0:5][0].to(device)).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a592655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_behave(model, optimizer, loss_fn, n_epochs=20):\n",
    "    for epoch in trange(n_epochs, desc=\"Epoch\"):\n",
    "        for context, target in behave_train_dataloader:\n",
    "            context = context.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(context)\n",
    "            \n",
    "            loss = loss_fn(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67ac60d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:16,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.2562390565872192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.2357738018035889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:02<00:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.003271222114563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:03<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 0.9992084503173828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:03<00:11,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9895802736282349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:04<00:10,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.1596808433532715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:05<00:09,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.1765990257263184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:06<00:09,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 1.1189799308776855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:07<00:08,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 1.10977041721344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:07<00:07,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.944463312625885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:08<00:06,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.8962883949279785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:09<00:06,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.8975445032119751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:10<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 1.0299983024597168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:10<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.8552301526069641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:11<00:03,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 1.1039438247680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:12<00:03,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 1.0020859241485596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:13<00:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.9543187022209167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:14<00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 1.0229499340057373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:14<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.877811849117279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:15<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 1.0309011936187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_behave(tst_MLP_attn, optimizer, loss_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ae4a931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  tensor(0.6389, device='cuda:0')\n",
      "Validation accuracy:  tensor(0.5101, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", evaluate_model_dataloader(tst_MLP_attn, behave_train_dataloader))\n",
    "print(\"Validation accuracy: \", evaluate_model_dataloader(tst_MLP_attn, behave_val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83141d84",
   "metadata": {},
   "source": [
    "MLP with no attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c9150ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "tst_MLP_no_attn = ConjugationMLP(embedding=embeddings_train, use_attention=False).to(device)\n",
    "optimizer = optim.Adam(tst_MLP_no_attn.parameters())\n",
    "loss_fnc = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95063451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:14,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.3417067527770996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:13,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.150078535079956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:02<00:12,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1661865711212158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:02<00:11,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.2251933813095093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:03<00:10,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9226757884025574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:04<00:09,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.1862858533859253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:05<00:09,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.0736894607543945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:05<00:08,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9538249969482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:06<00:07,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.8634957671165466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:07<00:07,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 1.1253666877746582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:07<00:06,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9879416227340698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:08<00:05,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.976795494556427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:09<00:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.9637759923934937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:10<00:04,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.9614425301551819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:10<00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.967290461063385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:11<00:02,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 1.0905230045318604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:12<00:02,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.8454235196113586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:12<00:01,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 1.049432396888733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:13<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.9667262434959412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:14<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 1.0290871858596802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_behave(tst_MLP_no_attn, optimizer, loss_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd82862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  tensor(0.6411, device='cuda:0')\n",
      "Validation accuracy:  tensor(0.5111, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", evaluate_model_dataloader(tst_MLP_no_attn, behave_train_dataloader))\n",
    "print(\"Validation accuracy: \", evaluate_model_dataloader(tst_MLP_no_attn, behave_val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f444cf",
   "metadata": {},
   "source": [
    "RNN for be-have conjugation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad5261db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConjugationRNN(nn.Module):\n",
    "    def __init__(self, embedding=None, context_size=CONTEXT_SIZE, rnn_hidden_size=128, rnn_num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        \n",
    "        (vocab_size, embedding_dim) = embedding.weight.shape\n",
    "        # Instantiate an embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Load the pretrained weights\n",
    "        self.embedding.load_state_dict(embedding.state_dict())\n",
    "        # Freeze the layer\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=self.rnn_hidden_size, num_layers=self.rnn_num_layers,\n",
    "            batch_first=True)\n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size * context_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        # out is now of shape (N, context_size, embedding_dim)\n",
    "\n",
    "        # LSTM layer\n",
    "        out, _ = self.lstm(out)\n",
    "        # out is now of shape (N, context_size, hidden_size)\n",
    "\n",
    "        out = F.relu(self.fc1(torch.flatten(out, 1)))\n",
    "        # out is now of shape (N, context_size*hidden_size)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5979fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "tst_RNN = ConjugationRNN(embedding=embeddings_train).to(device)\n",
    "optimizer = optim.Adam(tst_RNN.parameters())\n",
    "loss_fnc = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b96074d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:01<00:21,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.0712254047393799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:16,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.1797449588775635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:02<00:14,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1093422174453735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:03<00:13,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.062217354774475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:04<00:12,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9340625405311584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:05<00:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.039075255393982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:05<00:10,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.1482490301132202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:06<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9094465970993042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:07<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.8865634202957153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:08<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.7995813488960266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:09<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9794569611549377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:09<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.8628477454185486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:10<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.7104310989379883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:11<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.7543728947639465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:12<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.7930043339729309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:13<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 0.7462414503097534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:13<00:02,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.8307874798774719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:14<00:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 0.7527005076408386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:15<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.5843532085418701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:16<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 0.7483294606208801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_behave(tst_RNN, optimizer, loss_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1670976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  tensor(0.7087, device='cuda:0')\n",
      "Validation accuracy:  tensor(0.5387, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", evaluate_model_dataloader(tst_RNN, behave_train_dataloader))\n",
    "print(\"Validation accuracy: \", evaluate_model_dataloader(tst_RNN, behave_val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ed9e8",
   "metadata": {},
   "source": [
    "Be-have conjugation model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee881904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def behave_grid_search_generator():\n",
    "    for n_epochs in [15, 20]:\n",
    "        for model_class in [\"MLP\", \"RNN\"]:\n",
    "            match model_class:\n",
    "                case \"MLP\":\n",
    "                    for use_attention in [False, True]:\n",
    "                        torch.manual_seed(seed)\n",
    "                        model = ConjugationMLP(embedding=embeddings_train, use_attention=use_attention).to(device)\n",
    "                        yield model, [n_epochs, model_class, use_attention]\n",
    "                case \"RNN\":\n",
    "                    for n_layers in [1, 2]:\n",
    "                        for hidden_size in [64, 128]:\n",
    "                            torch.manual_seed(seed)\n",
    "                            model = ConjugationRNN(embedding=embeddings_train, rnn_hidden_size=hidden_size, rnn_num_layers=n_layers).to(device)\n",
    "                            yield model, [n_epochs, model_class, n_layers, hidden_size]\n",
    "                case _:\n",
    "                    print(f\"Unrecognized model_class {model_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ed44320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[15, 'MLP', False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:00<00:10,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.3417067527770996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [00:01<00:09,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.150078535079956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [00:02<00:08,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1661865711212158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [00:02<00:07,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.2251933813095093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [00:03<00:06,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9226757884025574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [00:03<00:05,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.1862858533859253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [00:04<00:05,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.0736894607543945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [00:05<00:04,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9538249969482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [00:05<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.8634957671165466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [00:06<00:03,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 1.1253666877746582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [00:07<00:02,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9879416227340698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [00:07<00:01,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.976795494556427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [00:08<00:01,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.9637759923934937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.9614425301551819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.967290461063385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[15, 'MLP', True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:00<00:10,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.2562390565872192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [00:01<00:09,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.2357738018035889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [00:02<00:09,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.003271222114563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [00:03<00:08,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 0.9992084503173828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [00:03<00:07,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9895802736282349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [00:04<00:06,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.1596808433532715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [00:05<00:06,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.1765990257263184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [00:06<00:05,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 1.1189799308776855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [00:06<00:04,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 1.10977041721344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [00:07<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.944463312625885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [00:08<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.8962883949279785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [00:09<00:02,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.8975445032119751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [00:09<00:01,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 1.0299983024597168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [00:10<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.8552301526069641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 1.1039438247680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[15, 'RNN', 1, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:00<00:09,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.3904597759246826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [00:01<00:08,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.0446608066558838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [00:02<00:08,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1410789489746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [00:02<00:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 0.9526775479316711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [00:03<00:06,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 1.1271010637283325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [00:04<00:06,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.0442330837249756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [00:04<00:05,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 0.946201741695404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [00:05<00:04,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9583057165145874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [00:06<00:04,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 1.0073667764663696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [00:06<00:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.9580730199813843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [00:07<00:02,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 1.0159984827041626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [00:08<00:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 1.028897762298584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [00:08<00:01,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.9530931115150452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [00:09<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.9194236397743225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.8663085699081421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[15, 'RNN', 1, 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:00<00:10,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.0712254047393799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [00:01<00:10,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.1797449588775635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [00:02<00:09,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1093422174453735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [00:03<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.062217354774475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [00:03<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9340625405311584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [00:04<00:07,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.039075255393982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [00:05<00:06,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.1482490301132202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [00:06<00:05,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9094465970993042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [00:07<00:04,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.8865634202957153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [00:07<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.7995813488960266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [00:08<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9794569611549377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [00:09<00:02,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.8628477454185486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [00:10<00:01,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.7104310989379883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [00:10<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.7543728947639465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.7930043339729309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[15, 'RNN', 2, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:00<00:10,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.4043505191802979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [00:01<00:09,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.3601179122924805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [00:02<00:08,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 0.9937085509300232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [00:02<00:07,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.036586880683899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [00:03<00:07,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 1.0408214330673218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [00:04<00:06,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 0.940796971321106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [00:04<00:05,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.136170506477356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [00:05<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.999502956867218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [00:06<00:04,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.9840636849403381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [00:07<00:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 1.0145294666290283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [00:07<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9498229622840881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [00:08<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 1.0887012481689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [00:09<00:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.8150877952575684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.909991979598999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.9507534503936768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[15, 'RNN', 2, 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:00<00:10,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.4846348762512207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [00:01<00:08,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.1140023469924927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [00:02<00:08,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.0217491388320923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [00:02<00:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.0172748565673828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [00:03<00:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 1.1016746759414673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [00:04<00:06,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 0.9824539422988892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [00:04<00:05,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.030415654182434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [00:05<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.8708010911941528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [00:06<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 1.0426318645477295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [00:06<00:03,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.7948912382125854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [00:07<00:02,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.8549607992172241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [00:08<00:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 1.0234349966049194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [00:08<00:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.8591918349266052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [00:09<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.7199611663818359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.8643753528594971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[20, 'MLP', False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:10,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.3417067527770996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:10,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.150078535079956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:01<00:10,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1661865711212158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:02<00:10,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.2251933813095093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:03<00:09,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9226757884025574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:03<00:09,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.1862858533859253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:04<00:08,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.0736894607543945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:05<00:07,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9538249969482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:05<00:07,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.8634957671165466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:06<00:06,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 1.1253666877746582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:07<00:05,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9879416227340698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:07<00:05,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.976795494556427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:08<00:04,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.9637759923934937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:09<00:03,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.9614425301551819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:09<00:03,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.967290461063385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:10<00:02,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 1.0905230045318604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:11<00:01,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.8454235196113586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:11<00:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 1.049432396888733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:12<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.9667262434959412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:13<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 1.0290871858596802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[20, 'MLP', True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:14,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.2562390565872192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:13,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.2357738018035889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:02<00:12,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.003271222114563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:03<00:12,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 0.9992084503173828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:03<00:11,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9895802736282349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:04<00:10,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.1596808433532715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:05<00:09,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.1765990257263184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:06<00:09,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 1.1189799308776855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:06<00:08,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 1.10977041721344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:07<00:07,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.944463312625885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:08<00:06,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.8962883949279785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:09<00:06,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.8975445032119751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:09<00:05,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 1.0299983024597168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:10<00:04,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.8552301526069641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:11<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 1.1039438247680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:12<00:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 1.0020859241485596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:12<00:02,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.9543187022209167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:13<00:01,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 1.0229499340057373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:14<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.877811849117279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:15<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 1.0309011936187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[20, 'RNN', 1, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:13,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.3904597759246826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:12,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.0446608066558838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:02<00:12,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1410789489746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:02<00:11,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 0.9526775479316711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:03<00:10,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 1.1271010637283325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:04<00:09,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.0442330837249756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:04<00:09,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 0.946201741695404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:05<00:08,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9583057165145874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:06<00:07,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 1.0073667764663696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:07<00:06,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.9580730199813843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:07<00:06,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 1.0159984827041626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:08<00:05,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 1.028897762298584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:09<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.9530931115150452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:09<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.9194236397743225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:10<00:03,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.8663085699081421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:11<00:02,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 0.9208292961120605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:11<00:02,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 1.0345921516418457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:12<00:01,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 0.935599684715271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:13<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.8263096809387207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:13<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 0.829239010810852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[20, 'RNN', 1, 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.0712254047393799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.1797449588775635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:02<00:13,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1093422174453735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:03<00:12,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.062217354774475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:03<00:11,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9340625405311584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:04<00:10,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.039075255393982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:05<00:10,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.1482490301132202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:06<00:09,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9094465970993042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:06<00:08,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.8865634202957153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:07<00:07,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.7995813488960266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:08<00:07,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9794569611549377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:09<00:06,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.8628477454185486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:10<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.7104310989379883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:10<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.7543728947639465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:11<00:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.7930043339729309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:12<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 0.7462414503097534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:13<00:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.8307874798774719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:14<00:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 0.7527005076408386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:14<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.5843532085418701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:15<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 0.7483294606208801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[20, 'RNN', 2, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:13,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.4043505191802979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:12,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.3601179122924805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:02<00:12,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 0.9937085509300232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:02<00:11,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.036586880683899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:03<00:10,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 1.0408214330673218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:04<00:09,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 0.940796971321106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:04<00:09,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.136170506477356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:05<00:08,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.999502956867218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:06<00:07,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.9840636849403381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:07<00:07,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 1.0145294666290283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:07<00:06,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9498229622840881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:08<00:05,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 1.0887012481689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:09<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.8150877952575684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:09<00:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.909991979598999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:10<00:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.9507534503936768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:11<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 0.9590354561805725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:12<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.9659873247146606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:12<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 0.8820995092391968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:13<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.8834714889526367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:14<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 0.9794890880584717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[20, 'RNN', 2, 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:14,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 1.4846348762512207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [00:01<00:13,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.1140023469924927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [00:02<00:11,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.0217491388320923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [00:02<00:10,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 1.0172748565673828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [00:03<00:10,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 1.1016746759414673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [00:04<00:09,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 0.9824539422988892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [00:04<00:09,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 1.030415654182434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [00:05<00:08,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.8708010911941528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [00:06<00:07,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 1.0426318645477295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [00:06<00:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.7948912382125854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [00:07<00:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.8549607992172241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [00:08<00:05,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 1.0234349966049194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [00:09<00:05,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.8591918349266052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [00:09<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.7199611663818359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [00:10<00:03,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.8643753528594971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [00:11<00:02,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 0.9915347099304199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [00:12<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.7853351831436157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [00:12<00:01,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 0.7959012985229492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [00:13<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.8674218058586121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:14<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 0.8937193155288696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    conj_best_v_acc = 0\n",
    "    conj_best_model = None\n",
    "    conj_best_hyperparams = []\n",
    "    conj_best_acc = []\n",
    "\n",
    "    for model, hyperparams in behave_grid_search_generator():\n",
    "        n_epochs = hyperparams[0]\n",
    "        \n",
    "        print(f\"Training model with {hyperparams=}\")\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        loss_fnc = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        train_behave(model, optimizer, loss_fnc, n_epochs)\n",
    "        \n",
    "        t_acc = evaluate_model_dataloader(model, behave_train_dataloader)\n",
    "        v_acc = evaluate_model_dataloader(model, behave_val_dataloader)\n",
    "        \n",
    "        if v_acc > conj_best_v_acc or conj_best_v_acc == 0:\n",
    "            conj_best_model = model\n",
    "            conj_best_hyperparams = hyperparams\n",
    "            conj_best_acc = [t_acc, v_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a0616265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model hyperparameters are [20, 'RNN', 2, 128] with 0.5185546875 validation accuracy\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    print(f\"Best model hyperparameters are {conj_best_hyperparams} with {conj_best_acc[1]} validation accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0428ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAINING:\n",
    "    # Make sure this corresponds to the actual selected hyperparameters\n",
    "    conj_best_model = ConjugationMLP(embedding=embeddings_train, use_attention=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16e83c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conj_best_model = save_load_model(\n",
    "    filepath=SAVE_PATH + \"conjugation_model.pth\", model=conj_best_model, \n",
    "    model_instance=conj_best_model, force_save=TRAINING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "485a8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ConjugationRNN(\n",
       "   (embedding): Embedding(1880, 16)\n",
       "   (lstm): LSTM(16, 128, num_layers=2, batch_first=True)\n",
       "   (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "   (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
       " ),\n",
       " True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conj_best_model, TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3286cf",
   "metadata": {},
   "source": [
    "Running the best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "73cf099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on unseen data: 50.820%\n"
     ]
    }
   ],
   "source": [
    "conj_best_test_acc = evaluate_model_dataloader(conj_best_model, behave_test_dataloader)\n",
    "print(f'Performance on unseen data: {conj_best_test_acc*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8991654",
   "metadata": {},
   "source": [
    "## 2.3: text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "74e862d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_dataset_t, gen_train_context, gen_train_targets = create_dataset(\n",
    "    train_token, train_vocab, CONTEXT_SIZE, banned_words=[0], position=\"ahead\"\n",
    ")\n",
    "\n",
    "gen_val_dataset_t, gen_val_context, gen_val_targets = create_dataset(\n",
    "    val_token, train_vocab, CONTEXT_SIZE, banned_words=[0], position=\"ahead\"\n",
    ")\n",
    "\n",
    "gen_test_dataset_t, gen_test_context, gen_test_targets = create_dataset(\n",
    "    test_token, train_vocab, CONTEXT_SIZE, banned_words=[0], position=\"ahead\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d7a7046f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unknown words since that is no fun\n",
    "len(gen_train_targets[gen_train_targets == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9cefca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_dataloader = DataLoader(gen_train_dataset_t, batch_size=1024, shuffle=True)\n",
    "gen_val_dataloader = DataLoader(gen_val_dataset_t, batch_size=1024, shuffle=True)\n",
    "gen_test_dataloader = DataLoader(gen_test_dataset_t, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca04705",
   "metadata": {},
   "source": [
    "Pure RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3581fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextWordRNN(nn.Module):\n",
    "    def __init__(self, embedding=None, context_size=CONTEXT_SIZE, rnn_hidden_size=128, rnn_num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        \n",
    "        (self.vocab_size, self.embedding_dim) = embedding.weight.shape\n",
    "        # Instantiate an embedding layer\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        # Load the pretrained weights\n",
    "        self.embedding.load_state_dict(embedding.state_dict())\n",
    "        # Freeze the layer\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(\n",
    "            self.embedding_dim, self.embedding_dim, rnn_num_layers,\n",
    "            batch_first=True)\n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Linear(self.embedding_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, self.vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out = self.embedding(x)\n",
    "        # out is now of shape (N, context_size, embedding_dim)\n",
    "\n",
    "        # RNN layer\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        # out is now of shape (N, context_size, hidden_size)\n",
    "\n",
    "        #out = F.relu(self.fc1(torch.flatten(out, 1)))\n",
    "        out = out.contiguous().mean(1).view(-1, self.embedding_dim)\n",
    "        # out is now of shape (N, context_size*hidden_size)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.rnn_num_layers, batch_size, self.embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62fa99",
   "metadata": {},
   "source": [
    "RNN with attention (probably not the best idea...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1380059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimusBad(nn.Module):\n",
    "    def __init__(self, embedding=None, context_size=CONTEXT_SIZE, rnn_hidden_size=128, rnn_num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        \n",
    "        (self.vocab_size, self.embedding_dim) = embedding.weight.shape\n",
    "        # Instantiate an embedding layer\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        # Load the pretrained weights\n",
    "        self.embedding.load_state_dict(embedding.state_dict())\n",
    "        # Freeze the layer\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.rnn = nn.RNN(\n",
    "            self.embedding_dim, self.embedding_dim, rnn_num_layers,\n",
    "            batch_first=True)\n",
    "        \n",
    "        self.multihead = MultiheadAttention(p=self.embedding_dim, num_heads=4, context_size=100).to(device)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(self.embedding_dim)\n",
    "        \n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Linear(self.embedding_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, self.vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out = self.embedding(x)\n",
    "        # out is now of shape (N, context_size, embedding_dim)\n",
    "\n",
    "        out = self.multihead(out) + out\n",
    "\n",
    "        out = self.layer_norm(out)\n",
    "\n",
    "        # LSTM layer\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        # out is now of shape (N, context_size, hidden_size)\n",
    "\n",
    "        #out = F.relu(self.fc1(torch.flatten(out, 1)))\n",
    "        out = out.contiguous().mean(1).view(-1, self.embedding_dim)\n",
    "        # out is now of shape (N, context_size*hidden_size)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.rnn_num_layers, batch_size, self.embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9727bd",
   "metadata": {},
   "source": [
    "Experimental training for NextWordRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a5e71fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "model_test = NextWordRNN(embedding=embeddings_train, rnn_hidden_size=128, rnn_num_layers=1).to(device)\n",
    "loss_fnc_test = nn.CrossEntropyLoss().to(device)\n",
    "optimizer_test = optim.Adam(model_test.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3a4bbc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextWordRNN(\n",
       "  (embedding): Embedding(1880, 16)\n",
       "  (rnn): RNN(16, 16, batch_first=True)\n",
       "  (fc1): Linear(in_features=16, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=1880, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a27f6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(model, loss_fn, optimizer, epochs):\n",
    "    for epoch in trange(epochs, desc=\"epochs\"):\n",
    "        for input, targets in gen_train_dataloader:\n",
    "            hidden = model.init_hidden(len(input)).to(device)\n",
    "\n",
    "            input = input.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output, hidden = model(input, hidden)\n",
    "            \n",
    "            # Detach hidden states\n",
    "            hidden = tuple([h.detach() for h in hidden])\n",
    "            \n",
    "            loss = loss_fn(output, targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca934df",
   "metadata": {},
   "source": [
    "Hyperparameter tuning for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6c37f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_gen_grid_search_generator():\n",
    "    for n_epochs in [10]:\n",
    "        for model_class in [\"Attention\", \"RNN\"]:\n",
    "            match model_class:\n",
    "                case \"Attention\":\n",
    "                    torch.manual_seed(seed)\n",
    "                    model = OptimusBad(embedding=embeddings_train).to(device)\n",
    "                    yield model, [n_epochs, model_class]\n",
    "                case \"RNN\":\n",
    "                    for hidden_size in [64]:\n",
    "                        torch.manual_seed(seed)\n",
    "                        model = NextWordRNN(embedding=embeddings_train, rnn_hidden_size=hidden_size).to(device)\n",
    "                        yield model, [n_epochs, model_class, hidden_size]\n",
    "                case _:\n",
    "                    print(f\"Unrecognized model_class {model_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "902788a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[10, 'Attention']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  10%|█         | 1/10 [00:15<02:17, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 4.893943786621094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  20%|██        | 2/10 [00:29<01:59, 14.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 4.260959625244141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  30%|███       | 3/10 [00:44<01:42, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 5.121345520019531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  40%|████      | 4/10 [00:58<01:26, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 3.806652307510376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  50%|█████     | 5/10 [01:12<01:11, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 4.445745944976807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  60%|██████    | 6/10 [01:26<00:57, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 4.232029914855957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  70%|███████   | 7/10 [01:40<00:42, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 4.40986442565918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  80%|████████  | 8/10 [01:55<00:28, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 4.543718338012695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  90%|█████████ | 9/10 [02:09<00:14, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 3.876676082611084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 10/10 [02:24<00:00, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 4.669893264770508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hyperparams=[10, 'RNN', 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  10%|█         | 1/10 [00:12<01:54, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 4.525826930999756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  20%|██        | 2/10 [00:25<01:40, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 4.447353363037109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  30%|███       | 3/10 [00:37<01:26, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 4.51756477355957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  40%|████      | 4/10 [00:50<01:15, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 4.244434356689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  50%|█████     | 5/10 [01:03<01:03, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 5.079143524169922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  60%|██████    | 6/10 [01:15<00:50, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 4.6272292137146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  70%|███████   | 7/10 [01:28<00:37, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 4.4193549156188965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  80%|████████  | 8/10 [01:40<00:25, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 4.428864002227783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:  90%|█████████ | 9/10 [01:53<00:12, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 3.952335834503174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 10/10 [02:05<00:00, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 4.398306369781494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    gen_best_v_acc = 0\n",
    "    gen_best_model = None\n",
    "    gen_best_hyperparams = []\n",
    "    gen_best_acc = []\n",
    "\n",
    "    for model, hyperparams in text_gen_grid_search_generator():\n",
    "        n_epochs = hyperparams[0]\n",
    "        \n",
    "        print(f\"Training model with {hyperparams=}\")\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        loss_fnc = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        train_generator(model, loss_fnc, optimizer, n_epochs)\n",
    "        \n",
    "        t_acc = evaluate_model_dataloader(model, gen_train_dataloader, hidden_arg=True)\n",
    "        v_acc = evaluate_model_dataloader(model, gen_val_dataloader, hidden_arg=True)\n",
    "        \n",
    "        if v_acc > gen_best_v_acc or gen_best_v_acc == 0:\n",
    "            gen_best_model = model\n",
    "            gen_best_hyperparams = hyperparams\n",
    "            gen_best_acc = [t_acc, v_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b329b5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model hyperparameters are [10, 'RNN', 64] with 0.15322503447532654 validation accuracy\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    print(f\"Best model hyperparameters are {gen_best_hyperparams} with {gen_best_acc[1]} validation accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4892fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAINING:\n",
    "    # TODO: Make sure this corresponds to the actual selected hyperparameters\n",
    "    gen_best_model = NextWordRNN(embedding=embeddings_train).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5deac8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_best_model = save_load_model(\n",
    "    filepath=SAVE_PATH + \"generation_model.pth\", model=gen_best_model,\n",
    "    model_instance=gen_best_model, force_save=TRAINING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4d307d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NextWordRNN(\n",
       "   (embedding): Embedding(1880, 16)\n",
       "   (rnn): RNN(16, 16, batch_first=True)\n",
       "   (fc1): Linear(in_features=16, out_features=256, bias=True)\n",
       "   (fc2): Linear(in_features=256, out_features=1880, bias=True)\n",
       " ),\n",
       " True)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_best_model, TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "33a4f55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextWordRNN(\n",
       "  (embedding): Embedding(1880, 16)\n",
       "  (rnn): RNN(16, 16, batch_first=True)\n",
       "  (fc1): Linear(in_features=16, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=1880, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_best_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30420c3",
   "metadata": {},
   "source": [
    "Testing accuracy for the selected generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "27453f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model has 0.180 testing accuracy\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate_model_dataloader(gen_best_model, gen_test_dataloader, hidden_arg=True)\n",
    "print(f\"Selected model has {test_acc:.3f} testing accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1431d955",
   "metadata": {},
   "source": [
    "Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3a33f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'You are tall'.lower().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1e4e06cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = train_vocab.lookup_indices(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7c0766cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_t = None\n",
    "def get_next_word(sequence):\n",
    "    global hidden_t\n",
    "    print(sequence)\n",
    "    \n",
    "    hidden_test = gen_best_model.init_hidden(1).to(device) if len(sequence) == 1 else hidden_t\n",
    "    test_output, hidden_t = gen_best_model(torch.tensor(sequence).unsqueeze(0).to(device), hidden_test)\n",
    "    return sequence + test_output.argmax(dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2beb5488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 38, 885]\n",
      "[23, 38, 885, 702]\n",
      "[23, 38, 885, 702, 3]\n",
      "[23, 38, 885, 702, 3, 1879]\n",
      "[23, 38, 885, 702, 3, 1879, 99]\n",
      "[23, 38, 885, 702, 3, 1879, 99, 2]\n",
      "[23, 38, 885, 702, 3, 1879, 99, 2, 123]\n",
      "[23, 38, 885, 702, 3, 1879, 99, 2, 123, 5]\n",
      "[23, 38, 885, 702, 3, 1879, 99, 2, 123, 5, 2]\n",
      "[23, 38, 885, 702, 3, 1879, 99, 2, 123, 5, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you are tall francs . i t the same of the . the'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    start = get_next_word(start)\n",
    "\n",
    "' '.join(train_vocab.lookup_tokens(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e2d1b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 38, 885, 702, 3, 1879, 99, 2, 123, 5, 2, 3, 2]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64e7a4",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b2a4db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_get_next_word(sequence, hidden=gen_best_model.init_hidden(1).to(device), k=10):\n",
    "    test_output, hidden = gen_best_model(torch.tensor(sequence).unsqueeze(0).to(device), hidden)\n",
    "    return test_output.topk(dim=1, k=k), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "02285ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_sequence(sentence: str):\n",
    "    x = sentence.lower().split(' ')\n",
    "    init = train_vocab.lookup_indices(x)\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3afc1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = sentence_to_sequence(\"the world is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4a1a175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 327, 16]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "64a0b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_sentence(seq):\n",
    "    return ' '.join(train_vocab.lookup_tokens(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8c10f30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the world is'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_sentence(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "db0e56a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.topk(\n",
       " values=tensor([[8.4971, 6.5575, 6.2429, 6.2337, 6.2202, 5.7945, 5.7251, 5.6326, 5.5832,\n",
       "          5.4375]], device='cuda:0', grad_fn=<TopkBackward0>),\n",
       " indices=tensor([[ 17,   7, 256,  56, 213,   6, 208, 196, 207, 175]], device='cuda:0')),\n",
       " tensor([[[ 0.4233,  0.1558, -0.0112,  0.3377, -0.1675,  0.3315, -0.7761,\n",
       "           -0.7873,  0.9817,  0.5754,  0.4610,  0.2490, -0.0244, -0.0995,\n",
       "            0.5053,  0.1190]]], device='cuda:0', grad_fn=<CudnnRnnBackward0>))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_get_next_word(init) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "95395289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxHeapPriorityQueue:\n",
    "    def __init__(self, maxsize):\n",
    "        self.maxsize = maxsize\n",
    "        self.queue = []\n",
    "\n",
    "    def push(self, item, priority):\n",
    "        if len(self.queue) < self.maxsize:\n",
    "            heapq.heappush(self.queue, (-priority, item))\n",
    "        else:\n",
    "            heapq.heappushpop(self.queue, (-priority, item))\n",
    "\n",
    "    def pop(self):\n",
    "        if self.queue:\n",
    "            return heapq.heappop(self.queue)[1]\n",
    "        else:\n",
    "            raise IndexError(\"pop from an empty priority queue\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0eb9e9",
   "metadata": {},
   "source": [
    "Beam search, prioritized by the sum of each token's logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c1cc4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(sentence: str, beam_width: int = 10, sentence_length: int = 10):\n",
    "    paths = MaxHeapPriorityQueue(beam_width)\n",
    "    \n",
    "    init = sentence_to_sequence(sentence)\n",
    "    (values, indices), hidden = prob_get_next_word(init, k=beam_width)\n",
    "    \n",
    "    for value, index in zip(values[0].tolist(), indices[0].tolist()):\n",
    "        paths.push((value, init + [index], hidden), value)\n",
    "        \n",
    "    for _ in range(sentence_length - len(init) - 1):\n",
    "        new_paths = MaxHeapPriorityQueue(beam_width)\n",
    "        while paths:\n",
    "            prev_value, seq, hidden = paths.pop()\n",
    "\n",
    "            (values, indices), hidden = prob_get_next_word(seq, hidden=hidden, k=beam_width)\n",
    "            for value, index in zip(values[0].tolist(), indices[0].tolist()):\n",
    "                new_paths.push((value + prev_value, seq + [index], hidden), value + prev_value)\n",
    "                \n",
    "        paths = new_paths\n",
    "        \n",
    "    return paths.pop()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a6a21",
   "metadata": {},
   "source": [
    "Testing the beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "de367f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 327, 16, 175, 32, 527, 661, 40, 42, 12, 12, 5]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = beam_search(\"the world is\", beam_width=15, sentence_length=12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eab75b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the world is called from sea floor one who his his of'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_sentence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "723ab29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as a large <unk> <unk> which that which dear and and as'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = beam_search(\"As a large language model\", beam_width=15, sentence_length=12)\n",
    "sequence_to_sentence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5d034b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is already are with of and when and so as'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = beam_search(\"my name is\", beam_width=15, sentence_length=12)\n",
    "sequence_to_sentence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "30dc655a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we hast out with long or so so on of very for'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = beam_search(\"we\", beam_width=15, sentence_length=12)\n",
    "sequence_to_sentence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5169a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
